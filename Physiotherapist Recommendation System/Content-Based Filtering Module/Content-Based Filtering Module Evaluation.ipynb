{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad81d26",
   "metadata": {},
   "source": [
    "# Functional Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4baf0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_33036\\3295623442.py:69: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  monotonic_ratio = grp.apply(is_monotonic).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_33036\\3295623442.py:91: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comp_counts = cold10.groupby(\"user_id\").apply(comp_ok)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>U0995</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>U0996</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>U0997</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>U0998</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>U0999</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  A  B  C\n",
       "0     U0000  4  3  3\n",
       "1     U0001  4  3  3\n",
       "2     U0002  4  3  3\n",
       "3     U0003  4  3  3\n",
       "4     U0004  4  3  3\n",
       "..      ... .. .. ..\n",
       "995   U0995  4  3  3\n",
       "996   U0996  4  3  3\n",
       "997   U0997  4  3  3\n",
       "998   U0998  4  3  3\n",
       "999   U0999  4  3  3\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>top50_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, top50_count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>match_score</th>\n",
       "      <th>rank</th>\n",
       "      <th>u_city</th>\n",
       "      <th>p_city</th>\n",
       "      <th>u_specs</th>\n",
       "      <th>p_specs</th>\n",
       "      <th>u_time</th>\n",
       "      <th>p_time</th>\n",
       "      <th>u_age</th>\n",
       "      <th>p_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, trainer_id, match_score, rank, u_city, p_city, u_specs, p_specs, u_time, p_time, u_age, p_age]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>user_missing</th>\n",
       "      <th>physio_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_group</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>available_time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>preferred_specialties</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>serve_age_group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>specialities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trainer_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   field  user_missing  physio_missing\n",
       "0              age_group           0.0             NaN\n",
       "1         available_time           0.0             0.0\n",
       "2                   city           0.0             0.0\n",
       "3                 gender           0.0             0.0\n",
       "4                   name           NaN             0.0\n",
       "5  preferred_specialties           0.0             NaN\n",
       "6        serve_age_group           NaN             0.0\n",
       "7           specialities           NaN             0.0\n",
       "8             trainer_id           NaN             0.0\n",
       "9                user_id           0.0             NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  share\n",
       "0     A    0.4\n",
       "1     C    0.3\n",
       "2     B    0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>recommend_rank</th>\n",
       "      <th>match_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>cold_start_score</th>\n",
       "      <th>group</th>\n",
       "      <th>u_city</th>\n",
       "      <th>p_city</th>\n",
       "      <th>u_time</th>\n",
       "      <th>p_time</th>\n",
       "      <th>u_specs</th>\n",
       "      <th>p_specs</th>\n",
       "      <th>u_age</th>\n",
       "      <th>p_age</th>\n",
       "      <th>content_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>U0518</td>\n",
       "      <td>754</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.659</td>\n",
       "      <td>B</td>\n",
       "      <td>Bath</td>\n",
       "      <td>Bath</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Elderly Fitness, Flexibility, Powerlifting</td>\n",
       "      <td>Elderly Fitness, Powerlifting, Flexibility</td>\n",
       "      <td>elderly</td>\n",
       "      <td>youth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>U0763</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.636</td>\n",
       "      <td>B</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Sports-Specific, Prenatal Fitness, Functional ...</td>\n",
       "      <td>Prenatal Fitness, Functional Training, Sports-...</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>elderly</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>U0920</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.680</td>\n",
       "      <td>C</td>\n",
       "      <td>Bath</td>\n",
       "      <td>London</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Pilates, Weight Loss, Prenatal Fitness</td>\n",
       "      <td>Pilates, Weight Loss, Prenatal Fitness</td>\n",
       "      <td>youth</td>\n",
       "      <td>elderly</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  trainer_id  recommend_rank  match_score  final_score  \\\n",
       "5181   U0518         754               2        0.571        0.795   \n",
       "7632   U0763           7               3        0.571        0.766   \n",
       "9201   U0920         700               2        0.571        0.822   \n",
       "\n",
       "      cold_start_score group  u_city   p_city   u_time     p_time  \\\n",
       "5181             0.659     B    Bath     Bath  Evening    Morning   \n",
       "7632             0.636     B  Oxford  Bristol  Morning  Afternoon   \n",
       "9201             0.680     C    Bath   London  Evening  Afternoon   \n",
       "\n",
       "                                                u_specs  \\\n",
       "5181         Elderly Fitness, Flexibility, Powerlifting   \n",
       "7632  Sports-Specific, Prenatal Fitness, Functional ...   \n",
       "9201             Pilates, Weight Loss, Prenatal Fitness   \n",
       "\n",
       "                                                p_specs        u_age    p_age  \\\n",
       "5181         Elderly Fitness, Powerlifting, Flexibility      elderly    youth   \n",
       "7632  Prenatal Fitness, Functional Training, Sports-...  middle-aged  elderly   \n",
       "9201             Pilates, Weight Loss, Prenatal Fitness        youth  elderly   \n",
       "\n",
       "      content_components  \n",
       "5181                   2  \n",
       "7632                   2  \n",
       "9201                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sheets_ok': True,\n",
       " 'match_score_agree_ratio': 0.81898,\n",
       " 'top50_size_ok_ratio': 1.0,\n",
       " 'top50_monotonic_ratio': 1.0,\n",
       " 'final_score_consistency_ratio': 1.0,\n",
       " 'top10_count_ok_ratio': 1.0,\n",
       " 'num_users_lt50': 0,\n",
       " 'overall_group_share': {'A': 0.4, 'C': 0.3, 'B': 0.3}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional testing for the Content Matching & Cold-Start modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "path = \"Content_Reco.xlsx\"\n",
    "xls = pd.ExcelFile(path)\n",
    "user = pd.read_excel(xls, \"user\")\n",
    "physio = pd.read_excel(xls, \"physio\")\n",
    "gA = pd.read_excel(xls, \"GroupA_Rank\")\n",
    "gB = pd.read_excel(xls, \"GroupB_Rank\")\n",
    "gC = pd.read_excel(xls, \"GroupC_Rank\")\n",
    "top50 = pd.read_excel(xls, \"top50_match_rank\")\n",
    "cold10 = pd.read_excel(xls, \"cold_start_top10\")\n",
    "\n",
    "# Basic checks\n",
    "sheets_ok = set(xls.sheet_names) >= {\"user\",\"physio\",\"GroupA_Rank\",\"GroupB_Rank\",\"GroupC_Rank\",\"top50_match_rank\",\"cold_start_top10\"}\n",
    "\n",
    "# --------------------\n",
    "# Helper: split specialties for matching\n",
    "# --------------------\n",
    "def specialties_overlap(user_spec, trainer_spec):\n",
    "    if pd.isna(user_spec) or pd.isna(trainer_spec):\n",
    "        return 0\n",
    "    us = [s.strip().lower() for s in str(user_spec).split(\",\")]\n",
    "    ts = [s.strip().lower() for s in str(trainer_spec).split(\",\")]\n",
    "    return int(len(set(us) & set(ts)) > 0)\n",
    "\n",
    "# Recompute raw_score for each (user, trainer) pair present in top50\n",
    "# Join necessary attributes\n",
    "u_cols = [\"user_id\",\"gender\",\"city\",\"preferred_specialties\",\"available_time\",\"age_group\"]\n",
    "p_cols = [\"trainer_id\",\"gender\",\"city\",\"specialities\",\"available_time\",\"serve_age_group\"]\n",
    "u = user[u_cols].rename(columns={\"gender\":\"u_gender\",\"city\":\"u_city\",\"preferred_specialties\":\"u_specs\",\"available_time\":\"u_time\",\"age_group\":\"u_age\"})\n",
    "p = physio[p_cols].rename(columns={\"gender\":\"p_gender\",\"city\":\"p_city\",\"specialities\":\"p_specs\",\"available_time\":\"p_time\",\"serve_age_group\":\"p_age\"})\n",
    "\n",
    "tp = top50.merge(u, on=\"user_id\", how=\"left\").merge(p, on=\"trainer_id\", how=\"left\")\n",
    "\n",
    "# Compute component matches\n",
    "comp = pd.DataFrame({\n",
    "    \"gender_m\": (tp[\"u_gender\"] == tp[\"p_gender\"]).astype(int),\n",
    "    \"city_m\": (tp[\"u_city\"] == tp[\"p_city\"]).astype(int),\n",
    "    \"time_m\": (tp[\"u_time\"] == tp[\"p_time\"]).astype(int),\n",
    "    \"age_m\": (tp[\"u_age\"] == tp[\"p_age\"]).astype(int),\n",
    "})\n",
    "\n",
    "spec_m = tp.apply(lambda r: specialties_overlap(r[\"u_specs\"], r[\"p_specs\"]), axis=1)\n",
    "comp[\"spec_m\"] = spec_m.values\n",
    "\n",
    "# Raw score and match_score recompute\n",
    "tp[\"raw_recalc\"] = comp.sum(axis=1)\n",
    "tp[\"match_recalc\"] = tp[\"raw_recalc\"] / 7.0\n",
    "\n",
    "# --------------------\n",
    "# 1.1 Flow correctness checks\n",
    "# --------------------\n",
    "\n",
    "# (a) Compare recalculated match_score with stored one\n",
    "tp[\"abs_diff_match\"] = (tp[\"match_recalc\"] - tp[\"match_score\"]).abs()\n",
    "match_score_agree_ratio = (tp[\"abs_diff_match\"] < 1e-6).mean()\n",
    "\n",
    "# (b) For each user, confirm top50 size (<=50) and monotonic non-increasing by match_score then rank\n",
    "grp = tp.sort_values([\"user_id\",\"match_score\",\"rank\"], ascending=[True, False, True]).groupby(\"user_id\")\n",
    "size_ok_ratio = (grp.size() <= 50).mean()\n",
    "# Monotonic check: within each user, match_score should be non-increasing with rank\n",
    "def is_monotonic(group):\n",
    "    g = group.sort_values(\"rank\")\n",
    "    return (g[\"match_score\"].diff().fillna(0) <= 1e-9).all()\n",
    "monotonic_ratio = grp.apply(is_monotonic).mean()\n",
    "\n",
    "# (c) Verify that cold_start_top10 trainers have final_score merged from the right group table\n",
    "# Build trainer->(group, final_score) map\n",
    "gA[\"group\"] = \"A\"; gB[\"group\"] = \"B\"; gC[\"group\"] = \"C\"\n",
    "trainer_info = pd.concat([gA[[\"trainer_id\",\"final_score\",\"group\"]],\n",
    "                          gB[[\"trainer_id\",\"final_score\",\"group\"]],\n",
    "                          gC[[\"trainer_id\",\"final_score\",\"group\"]]], ignore_index=True)\n",
    "\n",
    "c10 = cold10.merge(trainer_info, on=\"trainer_id\", how=\"left\", suffixes=(\"\",\"_from_group\"))\n",
    "# check final_score consistency (allow rounding to 3 decimals per your script)\n",
    "fs_consistent_ratio = (c10[\"final_score\"].round(3) == c10[\"final_score_from_group\"].round(3)).mean()\n",
    "\n",
    "# (d) Verify Top10 per user count == 10\n",
    "c10_counts = cold10.groupby(\"user_id\").size()\n",
    "top10_count_ok_ratio = (c10_counts == 10).mean()\n",
    "\n",
    "# (e) Verify group composition rule (A:4, B:3, C:3) where possible; allow fallback when不足\n",
    "def comp_ok(sub):\n",
    "    counts = sub[\"group\"].value_counts()\n",
    "    # accept either exact 4/3/3 or any composition summing to 10 when某组不足\n",
    "    return (counts.get(\"A\",0), counts.get(\"B\",0), counts.get(\"C\",0))\n",
    "comp_counts = cold10.groupby(\"user_id\").apply(comp_ok)\n",
    "comp_counts_df = comp_counts.apply(pd.Series).rename(columns={0:\"A\",1:\"B\",2:\"C\"})\n",
    "display(comp_counts_df.reset_index())\n",
    "\n",
    "# --------------------\n",
    "# 1.2 Fault case diagnostics\n",
    "# --------------------\n",
    "\n",
    "# Users with fewer than 50 candidates\n",
    "user_top50_counts = tp.groupby(\"user_id\").size()\n",
    "users_lt50 = user_top50_counts[user_top50_counts < 50]\n",
    "users_lt50_summary = pd.DataFrame({\"user_id\": users_lt50.index, \"top50_count\": users_lt50.values}).sort_values(\"top50_count\")\n",
    "display(users_lt50_summary)\n",
    "\n",
    "# Pairs with zero match_score in top50 (should be rare)\n",
    "zero_match_rows = tp[tp[\"match_score\"] <= 1e-9][[\"user_id\",\"trainer_id\",\"match_score\",\"rank\",\"u_city\",\"p_city\",\"u_specs\",\"p_specs\",\"u_time\",\"p_time\",\"u_age\",\"p_age\"]].head(50)\n",
    "display(zero_match_rows)\n",
    "\n",
    "# Missing features in user/physio and their impact\n",
    "missing_user = user.isna().sum()\n",
    "missing_physio = physio.isna().sum()\n",
    "missing_summary = pd.DataFrame({\"user_missing\": missing_user, \"physio_missing\": missing_physio})\n",
    "display(missing_summary.reset_index().rename(columns={\"index\":\"field\"}))\n",
    "\n",
    "# Does group dominance happen? check group distribution overall in cold10\n",
    "group_dist = cold10[\"group\"].value_counts(normalize=True).rename(\"share\")\n",
    "display(group_dist.reset_index().rename(columns={\"index\":\"group\"}))\n",
    "\n",
    "# --------------------\n",
    "# 1.3 Example anomaly explanation\n",
    "# Find top-ranked pairs where component matches are low (<=2/7) but recommended rank is high (<=3)\n",
    "c10_detail = cold10.merge(u, on=\"user_id\", how=\"left\").merge(p, on=\"trainer_id\", how=\"left\")\n",
    "def comp_score_row(r):\n",
    "    return int(r[\"u_gender\"]==r[\"p_gender\"]) + int(r[\"u_city\"]==r[\"p_city\"]) + int(r[\"u_time\"]==r[\"p_time\"]) + \\\n",
    "           specialties_overlap(r[\"u_specs\"], r[\"p_specs\"]) + int(r[\"u_age\"]==r[\"p_age\"])\n",
    "# compute content-only components for cold start top3 per user\n",
    "c10_top3 = c10_detail[c10_detail[\"recommend_rank\"]<=3].copy()\n",
    "c10_top3[\"content_components\"] = c10_top3.apply(comp_score_row, axis=1)\n",
    "# pick anomalies: high rank (1-3) but content_components <= 2\n",
    "anomalies = c10_top3[c10_top3[\"content_components\"] <= 2][\n",
    "    [\"user_id\",\"trainer_id\",\"recommend_rank\",\"match_score\",\"final_score\",\"cold_start_score\",\"group\",\n",
    "     \"u_city\",\"p_city\",\"u_time\",\"p_time\",\"u_specs\",\"p_specs\",\"u_age\",\"p_age\",\"content_components\"]\n",
    "].head(20)\n",
    "display(anomalies)\n",
    "\n",
    "# --------------------\n",
    "# Pack summary metrics for quick reference\n",
    "summary_metrics = {\n",
    "    \"sheets_ok\": bool(sheets_ok),\n",
    "    \"match_score_agree_ratio\": float(match_score_agree_ratio),\n",
    "    \"top50_size_ok_ratio\": float(size_ok_ratio),\n",
    "    \"top50_monotonic_ratio\": float(monotonic_ratio),\n",
    "    \"final_score_consistency_ratio\": float(fs_consistent_ratio),\n",
    "    \"top10_count_ok_ratio\": float(top10_count_ok_ratio),\n",
    "    \"num_users_lt50\": int(users_lt50.shape[0]),\n",
    "    \"overall_group_share\": group_dist.to_dict()\n",
    "}\n",
    "summary_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3fb17e",
   "metadata": {},
   "source": [
    "# Behaviroual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b86ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_33036\\3700726156.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  div_content = content_top10.groupby(\"user_id\").apply(lambda g: intra_list_diversity(g, \"p_specs\")).rename(\"ild_content\")\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_33036\\3700726156.py:105: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  div_cold = cold10_enriched.groupby(\"user_id\").apply(lambda g: intra_list_diversity(g, \"p_specs\")).rename(\"ild_cold\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>p_at_10_content</th>\n",
       "      <th>p_at_10_cold</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>U0995</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>U0996</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>U0997</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>U0998</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>U0999</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  p_at_10_content  p_at_10_cold  delta\n",
       "0     U0000              0.1           0.0   -0.1\n",
       "1     U0001              0.5           0.2   -0.3\n",
       "2     U0002              0.7           0.2   -0.5\n",
       "3     U0003              0.3           0.2   -0.1\n",
       "4     U0004              0.1           0.0   -0.1\n",
       "..      ...              ...           ...    ...\n",
       "995   U0995              0.5           0.2   -0.3\n",
       "996   U0996              0.4           0.1   -0.3\n",
       "997   U0997              0.3           0.2   -0.1\n",
       "998   U0998              0.3           0.2   -0.1\n",
       "999   U0999              0.1           0.1    0.0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ild_content</th>\n",
       "      <th>ild_cold</th>\n",
       "      <th>entropy_content</th>\n",
       "      <th>entropy_cold</th>\n",
       "      <th>ild_delta</th>\n",
       "      <th>ent_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>0.819630</td>\n",
       "      <td>0.810370</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>0.033980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>0.847407</td>\n",
       "      <td>0.848148</td>\n",
       "      <td>1.088900</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.795926</td>\n",
       "      <td>1.029653</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>-0.014074</td>\n",
       "      <td>0.059247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>0.758148</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.897946</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.190954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.862593</td>\n",
       "      <td>1.029653</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.059247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>U0995</td>\n",
       "      <td>0.726296</td>\n",
       "      <td>0.681852</td>\n",
       "      <td>1.029653</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>-0.044444</td>\n",
       "      <td>0.059247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>U0996</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.784074</td>\n",
       "      <td>0.943348</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.100741</td>\n",
       "      <td>0.145552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>U0997</td>\n",
       "      <td>0.880370</td>\n",
       "      <td>0.857037</td>\n",
       "      <td>1.088900</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>U0998</td>\n",
       "      <td>0.734074</td>\n",
       "      <td>0.798519</td>\n",
       "      <td>1.029653</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>0.059247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>U0999</td>\n",
       "      <td>0.628889</td>\n",
       "      <td>0.836296</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>1.0889</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0.033980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  ild_content  ild_cold  entropy_content  entropy_cold  ild_delta  \\\n",
       "0     U0000     0.819630  0.810370         1.054920        1.0889  -0.009259   \n",
       "1     U0001     0.847407  0.848148         1.088900        1.0889   0.000741   \n",
       "2     U0002     0.810000  0.795926         1.029653        1.0889  -0.014074   \n",
       "3     U0003     0.758148  0.826667         0.897946        1.0889   0.068519   \n",
       "4     U0004     0.836667  0.862593         1.029653        1.0889   0.025926   \n",
       "..      ...          ...       ...              ...           ...        ...   \n",
       "995   U0995     0.726296  0.681852         1.029653        1.0889  -0.044444   \n",
       "996   U0996     0.683333  0.784074         0.943348        1.0889   0.100741   \n",
       "997   U0997     0.880370  0.857037         1.088900        1.0889  -0.023333   \n",
       "998   U0998     0.734074  0.798519         1.029653        1.0889   0.064444   \n",
       "999   U0999     0.628889  0.836296         1.054920        1.0889   0.207407   \n",
       "\n",
       "     ent_delta  \n",
       "0     0.033980  \n",
       "1     0.000000  \n",
       "2     0.059247  \n",
       "3     0.190954  \n",
       "4     0.059247  \n",
       "..         ...  \n",
       "995   0.059247  \n",
       "996   0.145552  \n",
       "997   0.000000  \n",
       "998   0.059247  \n",
       "999   0.033980  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>content_share</th>\n",
       "      <th>cold_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  content_share  cold_share\n",
       "0     A         0.3454         0.4\n",
       "1     B         0.3375         0.3\n",
       "2     C         0.3171         0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_content_A</th>\n",
       "      <th>avg_content_B</th>\n",
       "      <th>avg_content_C</th>\n",
       "      <th>avg_cold_A</th>\n",
       "      <th>avg_cold_B</th>\n",
       "      <th>avg_cold_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_content_A  avg_content_B  avg_content_C  avg_cold_A  avg_cold_B  \\\n",
       "0         0.3454         0.3375         0.3171         0.4         0.3   \n",
       "\n",
       "   avg_cold_C  \n",
       "0         0.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_match_content</th>\n",
       "      <th>avg_final_content</th>\n",
       "      <th>avg_match_cold</th>\n",
       "      <th>avg_final_cold</th>\n",
       "      <th>delta_match</th>\n",
       "      <th>delta_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0259</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>0.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0835</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0440</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.5626</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>0.2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0816</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>-0.043271</td>\n",
       "      <td>0.2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0142</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5858</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.8022</td>\n",
       "      <td>-0.057571</td>\n",
       "      <td>0.2164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U0746</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5858</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.8022</td>\n",
       "      <td>-0.057571</td>\n",
       "      <td>0.2164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U0332</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>0.2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U0506</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>-0.014686</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U0065</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>-0.086100</td>\n",
       "      <td>0.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U0751</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.7713</td>\n",
       "      <td>-0.086114</td>\n",
       "      <td>0.1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U0484</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>-0.057571</td>\n",
       "      <td>0.1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U0398</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>U0470</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>-0.129000</td>\n",
       "      <td>0.1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>U0216</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5901</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>0.1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>U0844</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5511</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>-0.057571</td>\n",
       "      <td>0.1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>U0353</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.5989</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>-0.057557</td>\n",
       "      <td>0.1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>U0083</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>-0.043229</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U0158</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>-0.043229</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U0467</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.5595</td>\n",
       "      <td>0.5854</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>-0.043171</td>\n",
       "      <td>0.1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>U0767</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>-0.057529</td>\n",
       "      <td>0.1915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  avg_match_content  avg_final_content  avg_match_cold  \\\n",
       "0    U0259           0.614286             0.5275          0.5710   \n",
       "1    U0835           0.714286             0.5802          0.5996   \n",
       "2    U0440           0.614286             0.5626          0.5710   \n",
       "3    U0816           0.628571             0.5523          0.5853   \n",
       "4    U0142           0.628571             0.5858          0.5710   \n",
       "5    U0746           0.628571             0.5858          0.5710   \n",
       "6    U0332           0.600000             0.5447          0.5853   \n",
       "7    U0506           0.614286             0.5690          0.5996   \n",
       "8    U0065           0.700000             0.5580          0.6139   \n",
       "9    U0751           0.685714             0.5720          0.5996   \n",
       "10   U0484           0.628571             0.5683          0.5710   \n",
       "11   U0398           0.714286             0.5615          0.5996   \n",
       "12   U0470           0.700000             0.5584          0.5710   \n",
       "13   U0216           0.714286             0.5901          0.5996   \n",
       "14   U0844           0.628571             0.5511          0.5710   \n",
       "15   U0353           0.642857             0.5989          0.5853   \n",
       "16   U0083           0.671429             0.5643          0.6282   \n",
       "17   U0158           0.671429             0.5643          0.6282   \n",
       "18   U0467           0.628571             0.5595          0.5854   \n",
       "19   U0767           0.671429             0.5758          0.6139   \n",
       "\n",
       "    avg_final_cold  delta_match  delta_final  \n",
       "0           0.7541    -0.043286       0.2266  \n",
       "1           0.8065    -0.114686       0.2263  \n",
       "2           0.7839    -0.043286       0.2213  \n",
       "3           0.7717    -0.043271       0.2194  \n",
       "4           0.8022    -0.057571       0.2164  \n",
       "5           0.8022    -0.057571       0.2164  \n",
       "6           0.7598    -0.014700       0.2151  \n",
       "7           0.7721    -0.014686       0.2031  \n",
       "8           0.7588    -0.086100       0.2008  \n",
       "9           0.7713    -0.086114       0.1993  \n",
       "10          0.7655    -0.057571       0.1972  \n",
       "11          0.7578    -0.114686       0.1963  \n",
       "12          0.7539    -0.129000       0.1955  \n",
       "13          0.7840    -0.114686       0.1939  \n",
       "14          0.7448    -0.057571       0.1937  \n",
       "15          0.7923    -0.057557       0.1934  \n",
       "16          0.7574    -0.043229       0.1931  \n",
       "17          0.7574    -0.043229       0.1931  \n",
       "18          0.7517    -0.043171       0.1922  \n",
       "19          0.7673    -0.057529       0.1915  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'precision_content_mean': 0.3992,\n",
       " 'precision_cold_mean': 0.20540000000000003,\n",
       " 'precision_delta_mean': -0.1938,\n",
       " 'ild_content_mean': 0.7957896296296296,\n",
       " 'ild_cold_mean': 0.8302896296296296,\n",
       " 'ild_delta_mean': 0.03449999999999999,\n",
       " 'ent_content_mean': 0.9871843796379561,\n",
       " 'ent_cold_mean': 1.088899975342224,\n",
       " 'ent_delta_mean': 0.10171559570426773}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Behavioural testing for the Content Matching & Cold-Start modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "path = \"Content_Reco.xlsx\"\n",
    "xls = pd.ExcelFile(path)\n",
    "user = pd.read_excel(xls, \"user\")\n",
    "physio = pd.read_excel(xls, \"physio\")\n",
    "gA = pd.read_excel(xls, \"GroupA_Rank\")\n",
    "gB = pd.read_excel(xls, \"GroupB_Rank\")\n",
    "gC = pd.read_excel(xls, \"GroupC_Rank\")\n",
    "top50 = pd.read_excel(xls, \"top50_match_rank\")\n",
    "cold10 = pd.read_excel(xls, \"cold_start_top10\")\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "def split_list(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    return [s.strip().lower() for s in str(x).split(\",\") if s.strip()]\n",
    "\n",
    "def specialties_overlap(a, b):\n",
    "    sa, sb = set(split_list(a)), set(split_list(b))\n",
    "    return int(len(sa & sb) > 0)\n",
    "\n",
    "def content_components(row):\n",
    "    # five components: gender, city, time, specialities, age group\n",
    "    c = 0\n",
    "    c += int(row[\"u_gender\"] == row[\"p_gender\"])\n",
    "    c += int(row[\"u_city\"] == row[\"p_city\"])\n",
    "    c += int(row[\"u_time\"] == row[\"p_time\"])\n",
    "    c += specialties_overlap(row[\"u_specs\"], row[\"p_specs\"])\n",
    "    c += int(row[\"u_age\"] == row[\"p_age\"])\n",
    "    return c\n",
    "\n",
    "def jaccard_distance(a, b):\n",
    "    sa, sb = set(split_list(a)), set(split_list(b))\n",
    "    if not sa and not sb:\n",
    "        return 0.0\n",
    "    return 1.0 - (len(sa & sb) / max(1, len(sa | sb)))\n",
    "\n",
    "def intra_list_diversity(df_items, col_specs):\n",
    "    pairs = list(combinations(df_items.index, 2))\n",
    "    if not pairs:\n",
    "        return np.nan\n",
    "    dists = []\n",
    "    for i, j in pairs:\n",
    "        dists.append(jaccard_distance(df_items.loc[i, col_specs], df_items.loc[j, col_specs]))\n",
    "    return float(np.mean(dists))\n",
    "\n",
    "def group_entropy(values):\n",
    "    vc = values.value_counts(normalize=True)\n",
    "    return float(-(vc * np.log(vc + 1e-12)).sum())\n",
    "\n",
    "# --------------------\n",
    "# Prepare merged views\n",
    "# --------------------\n",
    "u = user.rename(columns={\"gender\":\"u_gender\",\"city\":\"u_city\",\"preferred_specialties\":\"u_specs\",\n",
    "                         \"available_time\":\"u_time\",\"age_group\":\"u_age\"})\n",
    "p = physio.rename(columns={\"gender\":\"p_gender\",\"city\":\"p_city\",\"specialities\":\"p_specs\",\n",
    "                           \"available_time\":\"p_time\",\"serve_age_group\":\"p_age\"})\n",
    "\n",
    "# Trainer group/final_score map\n",
    "gA[\"group\"] = \"A\"; gB[\"group\"] = \"B\"; gC[\"group\"] = \"C\"\n",
    "trainer_group = pd.concat([gA[[\"trainer_id\",\"final_score\",\"group\"]],\n",
    "                           gB[[\"trainer_id\",\"final_score\",\"group\"]],\n",
    "                           gC[[\"trainer_id\",\"final_score\",\"group\"]]], ignore_index=True)\n",
    "\n",
    "# Build content top10 per user from top50 (by match_score desc then rank asc)\n",
    "top50_sorted = top50.sort_values([\"user_id\",\"match_score\",\"rank\"], ascending=[True, False, True])\n",
    "content_top10 = top50_sorted.groupby(\"user_id\").head(10).copy()\n",
    "content_top10 = content_top10.merge(trainer_group, on=\"trainer_id\", how=\"left\")\n",
    "content_top10 = content_top10.merge(u[[\"user_id\",\"u_gender\",\"u_city\",\"u_specs\",\"u_time\",\"u_age\"]], on=\"user_id\", how=\"left\")\n",
    "content_top10 = content_top10.merge(p[[\"trainer_id\",\"p_gender\",\"p_city\",\"p_specs\",\"p_time\",\"p_age\"]], on=\"trainer_id\", how=\"left\")\n",
    "\n",
    "# Cold-start top10 enriched\n",
    "cold10_enriched = cold10.merge(u[[\"user_id\",\"u_gender\",\"u_city\",\"u_specs\",\"u_time\",\"u_age\"]], on=\"user_id\", how=\"left\")\n",
    "cold10_enriched = cold10_enriched.merge(p[[\"trainer_id\",\"p_gender\",\"p_city\",\"p_specs\",\"p_time\",\"p_age\"]], on=\"trainer_id\", how=\"left\")\n",
    "\n",
    "# --------------------\n",
    "# 1) Accuracy proxy: Precision@10 using content-components>=3 as \"relevant\"\n",
    "# --------------------\n",
    "content_top10[\"components\"] = content_top10.apply(content_components, axis=1)\n",
    "cold10_enriched[\"components\"] = cold10_enriched.apply(content_components, axis=1)\n",
    "\n",
    "# relevant if >=3 of 5 match\n",
    "content_rel = content_top10.assign(relevant=(content_top10[\"components\"]>=5).astype(int))\n",
    "cold_rel = cold10_enriched.assign(relevant=(cold10_enriched[\"components\"]>=5).astype(int))\n",
    "\n",
    "prec_content = content_rel.groupby(\"user_id\")[\"relevant\"].mean().rename(\"p_at_10_content\")\n",
    "prec_cold = cold_rel.groupby(\"user_id\")[\"relevant\"].mean().rename(\"p_at_10_cold\")\n",
    "\n",
    "prec_compare = pd.concat([prec_content, prec_cold], axis=1)\n",
    "prec_compare[\"delta\"] = prec_compare[\"p_at_10_cold\"] - prec_compare[\"p_at_10_content\"]\n",
    "\n",
    "# --------------------\n",
    "# 2) Diversity: intra-list diversity by specialties (Jaccard distance), and group-entropy\n",
    "# --------------------\n",
    "div_content = content_top10.groupby(\"user_id\").apply(lambda g: intra_list_diversity(g, \"p_specs\")).rename(\"ild_content\")\n",
    "div_cold = cold10_enriched.groupby(\"user_id\").apply(lambda g: intra_list_diversity(g, \"p_specs\")).rename(\"ild_cold\")\n",
    "\n",
    "ent_content = content_top10.groupby(\"user_id\")[\"group\"].apply(group_entropy).rename(\"entropy_content\")\n",
    "ent_cold = cold10_enriched.groupby(\"user_id\")[\"group\"].apply(group_entropy).rename(\"entropy_cold\")\n",
    "\n",
    "div_compare = pd.concat([div_content, div_cold, ent_content, ent_cold], axis=1)\n",
    "div_compare[\"ild_delta\"] = div_compare[\"ild_cold\"] - div_compare[\"ild_content\"]\n",
    "div_compare[\"ent_delta\"] = div_compare[\"entropy_cold\"] - div_compare[\"entropy_content\"]\n",
    "\n",
    "# --------------------\n",
    "# 3) Fairness: overall and average per-user group share before/after\n",
    "# --------------------\n",
    "def group_share(df):\n",
    "    return df[\"group\"].value_counts(normalize=True)\n",
    "\n",
    "overall_share_content = group_share(content_top10).rename(\"content_share\")\n",
    "overall_share_cold = group_share(cold10_enriched).rename(\"cold_share\")\n",
    "overall_share = pd.concat([overall_share_content, overall_share_cold], axis=1).fillna(0.0)\n",
    "\n",
    "# per-user average shares\n",
    "per_user_share_content = content_top10.pivot_table(index=\"user_id\", columns=\"group\", values=\"trainer_id\", aggfunc=\"count\").fillna(0)/10.0\n",
    "per_user_share_cold = cold10_enriched.pivot_table(index=\"user_id\", columns=\"group\", values=\"trainer_id\", aggfunc=\"count\").fillna(0)/10.0\n",
    "avg_share = pd.DataFrame({\n",
    "    \"avg_content_A\": per_user_share_content.get(\"A\", pd.Series(0,index=per_user_share_content.index)).mean(),\n",
    "    \"avg_content_B\": per_user_share_content.get(\"B\", pd.Series(0,index=per_user_share_content.index)).mean(),\n",
    "    \"avg_content_C\": per_user_share_content.get(\"C\", pd.Series(0,index=per_user_share_content.index)).mean(),\n",
    "    \"avg_cold_A\": per_user_share_cold.get(\"A\", pd.Series(0,index=per_user_share_cold.index)).mean(),\n",
    "    \"avg_cold_B\": per_user_share_cold.get(\"B\", pd.Series(0,index=per_user_share_cold.index)).mean(),\n",
    "    \"avg_cold_C\": per_user_share_cold.get(\"C\", pd.Series(0,index=per_user_share_cold.index)).mean(),\n",
    "}, index=[0])\n",
    "\n",
    "# --------------------\n",
    "# 4) Swap analysis: how cold-start trades off match_score vs final_score\n",
    "# --------------------\n",
    "# For each user, compute the difference in average match_score and average final_score between cold10 and content top10\n",
    "avg_content = content_top10.groupby(\"user_id\").agg(avg_match=(\"match_score\",\"mean\"), avg_final=(\"final_score\",\"mean\")).rename(columns={\"avg_match\":\"avg_match_content\",\"avg_final\":\"avg_final_content\"})\n",
    "avg_cold = cold10_enriched.groupby(\"user_id\").agg(avg_match=(\"match_score\",\"mean\"), avg_final=(\"final_score\",\"mean\")).rename(columns={\"avg_match\":\"avg_match_cold\",\"avg_final\":\"avg_final_cold\"})\n",
    "swap_summary = avg_content.join(avg_cold)\n",
    "swap_summary[\"delta_match\"] = swap_summary[\"avg_match_cold\"] - swap_summary[\"avg_match_content\"]\n",
    "swap_summary[\"delta_final\"] = swap_summary[\"avg_final_cold\"] - swap_summary[\"avg_final_content\"]\n",
    "\n",
    "# pick users with largest positive delta_final and negative delta_match (classic trade-off)\n",
    "swap_cases = swap_summary.sort_values([\"delta_final\",\"delta_match\"], ascending=[False, True]).head(20).reset_index()\n",
    "\n",
    "# --------------------\n",
    "# 5) Aggregate summaries for the paper\n",
    "# --------------------\n",
    "paper_stats = {\n",
    "    \"precision_content_mean\": float(prec_compare[\"p_at_10_content\"].mean()),\n",
    "    \"precision_cold_mean\": float(prec_compare[\"p_at_10_cold\"].mean()),\n",
    "    \"precision_delta_mean\": float(prec_compare[\"delta\"].mean()),\n",
    "    \"ild_content_mean\": float(div_compare[\"ild_content\"].mean()),\n",
    "    \"ild_cold_mean\": float(div_compare[\"ild_cold\"].mean()),\n",
    "    \"ild_delta_mean\": float(div_compare[\"ild_delta\"].mean()),\n",
    "    \"ent_content_mean\": float(div_compare[\"entropy_content\"].mean()),\n",
    "    \"ent_cold_mean\": float(div_compare[\"entropy_cold\"].mean()),\n",
    "    \"ent_delta_mean\": float(div_compare[\"ent_delta\"].mean()),\n",
    "}\n",
    "\n",
    "# --------------------\n",
    "# Display key tables\n",
    "# --------------------\n",
    "display(prec_compare.reset_index())\n",
    "display(div_compare.reset_index())\n",
    "display(overall_share.reset_index().rename(columns={\"index\":\"group\"}))\n",
    "display(avg_share)\n",
    "display(swap_cases)\n",
    "\n",
    "paper_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172a3ef9",
   "metadata": {},
   "source": [
    "# Decision Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c05d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(lambda g: (g[\"match_score\"] >= THRESH).mean()).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ild_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ent_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(lambda g: (g[\"match_score\"] >= THRESH).mean()).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ild_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ent_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(lambda g: (g[\"match_score\"] >= THRESH).mean()).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ild_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ent_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(lambda g: (g[\"match_score\"] >= THRESH).mean()).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ild_one).mean()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_30452\\2609982916.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"user_id\").apply(ent_one).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scheme</th>\n",
       "      <th>Precision@10(threshold=4/7)</th>\n",
       "      <th>ILD@10(specialities_diversity)</th>\n",
       "      <th>FairnessEntropy(group_balance)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ColdStart_Top10(0.5/0.5)</td>\n",
       "      <td>0.3311</td>\n",
       "      <td>0.830290</td>\n",
       "      <td>1.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content_Top10</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.795790</td>\n",
       "      <td>0.987184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML_Top10(final_score)</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.855446</td>\n",
       "      <td>0.992179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manual_Top10(0.6*match+0.4*final_norm)</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.818936</td>\n",
       "      <td>0.986562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Scheme  Precision@10(threshold=4/7)  \\\n",
       "0                ColdStart_Top10(0.5/0.5)                       0.3311   \n",
       "1                           Content_Top10                       0.6518   \n",
       "2                   ML_Top10(final_score)                       0.1385   \n",
       "3  Manual_Top10(0.6*match+0.4*final_norm)                       0.4418   \n",
       "\n",
       "   ILD@10(specialities_diversity)  FairnessEntropy(group_balance)  \n",
       "0                        0.830290                        1.088900  \n",
       "1                        0.795790                        0.987184  \n",
       "2                        0.855446                        0.992179  \n",
       "3                        0.818936                        0.986562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>Content_Top10</th>\n",
       "      <th>Manual_Top10(0.6*match+0.4*final_norm)</th>\n",
       "      <th>ML_Top10(final_score)</th>\n",
       "      <th>ColdStart_Top10(0.5/0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  Content_Top10  Manual_Top10(0.6*match+0.4*final_norm)  \\\n",
       "0     A         0.3454                                  0.3517   \n",
       "1     B         0.3375                                  0.3365   \n",
       "2     C         0.3171                                  0.3118   \n",
       "\n",
       "   ML_Top10(final_score)  ColdStart_Top10(0.5/0.5)  \n",
       "0                 0.3296                       0.4  \n",
       "1                 0.3461                       0.3  \n",
       "2                 0.3243                       0.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "path = \"Content_Reco.xlsx\"\n",
    "xls = pd.ExcelFile(path)\n",
    "user = pd.read_excel(xls, \"user\")\n",
    "physio = pd.read_excel(xls, \"physio\")\n",
    "gA = pd.read_excel(xls, \"GroupA_Rank\")\n",
    "gB = pd.read_excel(xls, \"GroupB_Rank\")\n",
    "gC = pd.read_excel(xls, \"GroupC_Rank\")\n",
    "top50 = pd.read_excel(xls, \"top50_match_rank\")\n",
    "cold10 = pd.read_excel(xls, \"cold_start_top10\")\n",
    "\n",
    "# --------------------\n",
    "# Build trainer info: final_score + group + specialities\n",
    "# --------------------\n",
    "gA = gA.copy(); gA[\"group\"] = \"A\"\n",
    "gB = gB.copy(); gB[\"group\"] = \"B\"\n",
    "gC = gC.copy(); gC[\"group\"] = \"C\"\n",
    "\n",
    "trainer_group = pd.concat(\n",
    "    [\n",
    "        gA[[\"trainer_id\", \"final_score\", \"group\"]],\n",
    "        gB[[\"trainer_id\", \"final_score\", \"group\"]],\n",
    "        gC[[\"trainer_id\", \"final_score\", \"group\"]],\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "trainer_specs = physio[[\"trainer_id\", \"specialities\"]]\n",
    "trainer_info = trainer_group.merge(trainer_specs, on=\"trainer_id\", how=\"left\")\n",
    "\n",
    "# Normalize final_score (for manual weighted composite)\n",
    "fs_min, fs_max = trainer_info[\"final_score\"].min(), trainer_info[\"final_score\"].max()\n",
    "trainer_info[\"final_score_norm\"] = (trainer_info[\"final_score\"] - fs_min) / (fs_max - fs_min + 1e-12)\n",
    "\n",
    "# Merge candidate pool with trainer info\n",
    "cand = top50.merge(trainer_info, on=\"trainer_id\", how=\"left\")\n",
    "\n",
    "# --------------------\n",
    "# Utility functions: harmonize columns & safe metric computation\n",
    "# --------------------\n",
    "def harmonize_columns(df):\n",
    "    \"\"\"Unify column names and fill missing values; return a copy.\"\"\"\n",
    "    out = df.copy()\n",
    "    # group\n",
    "    if \"group\" not in out.columns:\n",
    "        gx = out.get(\"group_x\"); gy = out.get(\"group_y\")\n",
    "        if gx is not None or gy is not None:\n",
    "            out[\"group\"] = (gy if gy is not None else pd.Series(index=out.index)).combine_first(\n",
    "                gx if gx is not None else pd.Series(index=out.index)\n",
    "            )\n",
    "        else:\n",
    "            out[\"group\"] = \"Unknown\"\n",
    "    out[\"group\"] = out[\"group\"].fillna(\"Unknown\")\n",
    "\n",
    "    # final_score\n",
    "    if \"final_score\" not in out.columns:\n",
    "        fx = out.get(\"final_score_x\"); fy = out.get(\"final_score_y\")\n",
    "        if fx is not None or fy is not None:\n",
    "            out[\"final_score\"] = (fx if fx is not None else pd.Series(index=out.index)).combine_first(\n",
    "                fy if fy is not None else pd.Series(index=out.index)\n",
    "            )\n",
    "\n",
    "    # specialities\n",
    "    if \"specialities\" not in out.columns:\n",
    "        out[\"specialities\"] = \"\"\n",
    "\n",
    "    # Keep user_id / trainer_id; if match_score is missing, downstream metrics handle it\n",
    "    return out\n",
    "\n",
    "THRESH = 4.0/7.0  # ≈ 0.5714\n",
    "\n",
    "def precision_at_10(df):\n",
    "    \"\"\"Compute Precision@10 if match_score exists, else return NaN.\"\"\"\n",
    "    if \"match_score\" not in df.columns:\n",
    "        return np.nan\n",
    "    return df.groupby(\"user_id\").apply(lambda g: (g[\"match_score\"] >= THRESH).mean()).mean()\n",
    "\n",
    "def ild_by_specs(df):\n",
    "    \"\"\"Compute ILD based on Jaccard distance of specialities.\"\"\"\n",
    "    def ild_one(g):\n",
    "        specs = g[\"specialities\"].fillna(\"\").astype(str).tolist()\n",
    "        pairs = list(combinations(range(len(specs)), 2))\n",
    "        if not pairs:\n",
    "            return np.nan\n",
    "        dists = []\n",
    "        for i, j in pairs:\n",
    "            sa = set([s.strip().lower() for s in specs[i].split(\",\") if s.strip()])\n",
    "            sb = set([s.strip().lower() for s in specs[j].split(\",\") if s.strip()])\n",
    "            if not sa and not sb:\n",
    "                d = 0.0\n",
    "            else:\n",
    "                inter = len(sa & sb)\n",
    "                union = len(sa | sb) if len(sa | sb) > 0 else 1\n",
    "                d = 1.0 - inter / union\n",
    "            dists.append(d)\n",
    "        return float(np.mean(dists))\n",
    "    return df.groupby(\"user_id\").apply(ild_one).mean()\n",
    "\n",
    "def fairness_entropy(df):\n",
    "    \"\"\"Compute entropy of group distribution for each user's recommendations.\"\"\"\n",
    "    if \"group\" not in df.columns:\n",
    "        df = harmonize_columns(df)\n",
    "    def ent_one(g):\n",
    "        if \"group\" not in g.columns:\n",
    "            return np.nan\n",
    "        p = g[\"group\"].value_counts(normalize=True)\n",
    "        return float(-(p * np.log(p + 1e-12)).sum())\n",
    "    return df.groupby(\"user_id\").apply(ent_one).mean()\n",
    "\n",
    "def overall_group_share(df):\n",
    "    \"\"\"Compute overall group share.\"\"\"\n",
    "    if \"group\" not in df.columns:\n",
    "        df = harmonize_columns(df)\n",
    "    return df[\"group\"].value_counts(normalize=True).rename(\"share\")\n",
    "\n",
    "# --------------------\n",
    "# Define four recommendation schemes\n",
    "# --------------------\n",
    "# A) Pure content: top10 by match_score\n",
    "content_top10 = (\n",
    "    cand.sort_values([\"user_id\", \"match_score\", \"rank\"], ascending=[True, False, True])\n",
    "        .groupby(\"user_id\")\n",
    "        .head(10)\n",
    ")\n",
    "content_top10 = harmonize_columns(content_top10)\n",
    "\n",
    "# B) Manual weighting: 0.6 * match_score + 0.4 * final_score_norm\n",
    "cand_manual = cand.copy()\n",
    "if \"match_score\" in cand_manual.columns:\n",
    "    cand_manual[\"manual_score\"] = 0.6 * cand_manual[\"match_score\"] + 0.4 * cand_manual[\"final_score_norm\"]\n",
    "else:\n",
    "    cand_manual[\"manual_score\"] = cand_manual[\"final_score_norm\"]\n",
    "manual_top10 = (\n",
    "    cand_manual.sort_values([\"user_id\", \"manual_score\", \"rank\"], ascending=[True, False, True])\n",
    "        .groupby(\"user_id\")\n",
    "        .head(10)\n",
    ")\n",
    "manual_top10 = harmonize_columns(manual_top10)\n",
    "\n",
    "# C) ML proxy: top10 by final_score only\n",
    "cand_ml = cand.copy()\n",
    "if \"final_score\" not in cand_ml.columns:\n",
    "    cand_ml = harmonize_columns(cand_ml)\n",
    "ml_top10 = (\n",
    "    cand_ml.sort_values([\"user_id\", \"final_score\", \"rank\"], ascending=[True, False, True])\n",
    "        .groupby(\"user_id\")\n",
    "        .head(10)\n",
    ")\n",
    "ml_top10 = harmonize_columns(ml_top10)\n",
    "\n",
    "# D) Current method: cold_start_top10 merged with trainer_info\n",
    "cold10_enriched = cold10.merge(trainer_info, on=\"trainer_id\", how=\"left\")\n",
    "cold10_enriched = harmonize_columns(cold10_enriched)\n",
    "\n",
    "# --------------------\n",
    "# (Optional) further cleanup: unify *_x / *_y columns\n",
    "# --------------------\n",
    "for col_base in [\"group\", \"final_score\"]:\n",
    "    x_col, y_col = f\"{col_base}_x\", f\"{col_base}_y\"\n",
    "    if x_col in cold10_enriched.columns or y_col in cold10_enriched.columns:\n",
    "        cold10_enriched[col_base] = cold10_enriched.get(x_col, pd.Series(index=cold10_enriched.index)).where(\n",
    "            cold10_enriched.get(x_col, pd.Series(index=cold10_enriched.index)).notna(),\n",
    "            cold10_enriched.get(y_col)\n",
    "        )\n",
    "        for c in [x_col, y_col]:\n",
    "            if c in cold10_enriched.columns:\n",
    "                cold10_enriched.drop(columns=c, inplace=True)\n",
    "\n",
    "# --------------------\n",
    "# Compute metrics for the four schemes\n",
    "# --------------------\n",
    "schemes = {\n",
    "    \"Content_Top10\": content_top10,\n",
    "    \"Manual_Top10(0.6*match+0.4*final_norm)\": manual_top10,\n",
    "    \"ML_Top10(final_score)\": ml_top10,\n",
    "    \"ColdStart_Top10(0.5/0.5)\": cold10_enriched\n",
    "}\n",
    "\n",
    "rows = []\n",
    "group_shares = []\n",
    "for name, df_s in schemes.items():\n",
    "    # Ensure required columns exist\n",
    "    df_s = harmonize_columns(df_s)\n",
    "\n",
    "    rows.append({\n",
    "        \"Scheme\": name,\n",
    "        \"Precision@10(threshold=4/7)\": precision_at_10(df_s),\n",
    "        \"ILD@10(specialities_diversity)\": ild_by_specs(df_s),\n",
    "        \"FairnessEntropy(group_balance)\": fairness_entropy(df_s)\n",
    "    })\n",
    "    gs = overall_group_share(df_s).reset_index().rename(columns={\"index\": \"group\", \"share\": name})\n",
    "    group_shares.append(gs)\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"Scheme\").reset_index(drop=True)\n",
    "\n",
    "# Combine group share tables\n",
    "group_share_df = group_shares[0]\n",
    "for gs in group_shares[1:]:\n",
    "    group_share_df = group_share_df.merge(gs, on=\"group\", how=\"outer\")\n",
    "group_share_df = group_share_df.fillna(0.0)\n",
    "\n",
    "# --------------------\n",
    "# Display results\n",
    "# --------------------\n",
    "display(results_df)\n",
    "display(group_share_df)\n",
    "\n",
    "# Export dictionary form if needed (for logging/export)\n",
    "_ = results_df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390ab32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
