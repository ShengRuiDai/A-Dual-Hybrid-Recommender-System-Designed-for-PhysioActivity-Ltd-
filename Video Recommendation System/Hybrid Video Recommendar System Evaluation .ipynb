{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8084e6c9",
   "metadata": {},
   "source": [
    "# Functional Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1575a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videos_info': (10000, 3),\n",
       " 'filtered_rate_data': (13893, 5),\n",
       " 'user_favorite_videos': (1000, 2),\n",
       " 'all_users_top10_recommendations': (10010, 8),\n",
       " 'user_behavior': (58605, 3)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------- 0. Load data -------------\n",
    "file_path = \"Hybrid_Reco_Videos_Data.xlsx\"\n",
    "videos = pd.read_excel(file_path, sheet_name=\"videos' info\")\n",
    "rates = pd.read_excel(file_path, sheet_name=\"filtered_rate_data\")\n",
    "favs = pd.read_excel(file_path, sheet_name=\"user_favorite_videos\")\n",
    "top10 = pd.read_excel(file_path, sheet_name=\"all_users_top10_recommendations\")\n",
    "behav = pd.read_excel(file_path, sheet_name=\"User behavior\")\n",
    "\n",
    "summary = {\n",
    "    \"videos_info\": videos.shape,\n",
    "    \"filtered_rate_data\": rates.shape,\n",
    "    \"user_favorite_videos\": favs.shape,\n",
    "    \"all_users_top10_recommendations\": top10.shape,\n",
    "    \"user_behavior\": behav.shape,\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de1040c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'missing': {'videos_info': {'video_id': 0, 'title': 0, 'specialities': 0},\n",
       "   'filtered_rate_data': {'user_id': 0,\n",
       "    'video_id': 0,\n",
       "    'trainer_id': 0,\n",
       "    'action_type': 0,\n",
       "    'rating_score': 0},\n",
       "   'user_favorite_videos': {'user_id': 0, 'favorite_title': 154},\n",
       "   'all_users_top10_recommendations': {'user_id': 0,\n",
       "    'rank': 0,\n",
       "    'video_id': 0,\n",
       "    'title': 0,\n",
       "    'hybrid_score': 0,\n",
       "    'popularity_score': 0,\n",
       "    'collab_score': 0,\n",
       "    'content_score': 0},\n",
       "   'user_behavior': {'user_id': 0, 'video_id': 0, 'action_type': 0}},\n",
       "  'duplicates': {'videos.video_id': 0, 'rates.user_video': 0, 'favs.user': 0},\n",
       "  'cross_sheet': {'rates.video_in_videos_info_missing': 0,\n",
       "   'behav.video_missing_in_videos_info': 0,\n",
       "   'top10.video_missing_in_videos_info': 0,\n",
       "   'favs.title_not_in_videos_title': 154}},\n",
       " 'U0296',\n",
       "   user_id  rank  video_id                                   title  \\\n",
       " 0   U0296     1     42505            Cardio Training Video #42505   \n",
       " 1   U0296     2     82210           Pilates Training Video #82210   \n",
       " 2   U0296     3     26602  Prenatal Fitness Training Video #26602   \n",
       " 3   U0296     4     66105           Pilates Training Video #66105   \n",
       " 4   U0296     5     31504              HIIT Training Video #31504   \n",
       " \n",
       "    hybrid_score  popularity_score  collab_score  content_score  \n",
       " 0      0.503434              1.00      0.525557            0.0  \n",
       " 1      0.496122              0.66      0.843401            0.0  \n",
       " 2      0.436970              0.38      0.944151            0.0  \n",
       " 3      0.330000              0.00      1.000000            0.0  \n",
       " 4      0.330000              0.00      0.000000            1.0  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------- 1.1 Data Integrity and Input/Output Validation -------------\n",
    "\n",
    "def data_integrity_report():\n",
    "    rep = {}\n",
    "    # Missing value statistics\n",
    "    rep['missing'] = {\n",
    "        \"videos_info\": videos.isna().sum().to_dict(),\n",
    "        \"filtered_rate_data\": rates.isna().sum().to_dict(),\n",
    "        \"user_favorite_videos\": favs.isna().sum().to_dict(),\n",
    "        \"all_users_top10_recommendations\": top10.isna().sum().to_dict(),\n",
    "        \"user_behavior\": behav.isna().sum().to_dict()\n",
    "    }\n",
    "    # Primary key duplicates\n",
    "    rep['duplicates'] = {\n",
    "        \"videos.video_id\": videos['video_id'].duplicated().sum(),\n",
    "        \"rates.user_video\": rates.duplicated(subset=['user_id','video_id']).sum(),\n",
    "        \"favs.user\": favs['user_id'].duplicated().sum()\n",
    "    }\n",
    "    # Cross-table ID consistency\n",
    "    rep['cross_sheet'] = {\n",
    "        \"rates.video_in_videos_info_missing\": int(~rates['video_id'].isin(videos['video_id']).any()),\n",
    "        \"behav.video_missing_in_videos_info\": int((~behav['video_id'].isin(videos['video_id'])).sum()),\n",
    "        \"top10.video_missing_in_videos_info\": int((~top10['video_id'].isin(videos['video_id'])).sum()),\n",
    "        \"favs.title_not_in_videos_title\": int((~favs['favorite_title'].isin(videos['title'])).sum()),\n",
    "    }\n",
    "    # Input-output validity example: take top10 for one user\n",
    "    sample_user = top10['user_id'].iloc[0]\n",
    "    sample_result = top10[top10['user_id']==sample_user].sort_values('rank').head(10)\n",
    "    return rep, sample_user, sample_result\n",
    "\n",
    "integrity_rep, sample_user, sample_result = data_integrity_report()\n",
    "integrity_rep, sample_user, sample_result.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0900d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\1318139453.py:152: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged[['popularity_score','collab_score','content_score']] = merged[['popularity_score','collab_score','content_score']].fillna(0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'missing_favorite_titles_or_not_found': 308,\n",
       " 'cold_start_user_count': 1,\n",
       " 'cold_start_user_example': 'U1000',\n",
       " 'videos_without_any_ratings': 3957,\n",
       " 'pop_top50_small_sample_count': 36,\n",
       " 'surprise_available': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------- 1.2 Functional Testing of Each Module: Implement Module Functions -------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Popularity ---\n",
    "video_stats = (rates.groupby('video_id')['rating_score']\n",
    "               .agg(avg_rating='mean', num_ratings='count')\n",
    "               .reset_index())\n",
    "popularity_join = videos[['video_id','title','specialities']].merge(video_stats, on='video_id', how='left')\n",
    "popularity_join['num_ratings'] = popularity_join['num_ratings'].fillna(0).astype(int)\n",
    "popularity_join['avg_rating'] = popularity_join['avg_rating'].fillna(popularity_join['avg_rating'].mean())\n",
    "\n",
    "def get_top_popular_videos(df=popularity_join, n=10, min_ratings=5):\n",
    "    filtered = df[df['num_ratings']>=min_ratings].copy()\n",
    "    ranked = filtered.sort_values(['avg_rating','num_ratings'], ascending=[False, False]).head(n)\n",
    "    return ranked[['video_id','title','avg_rating','num_ratings']]\n",
    "\n",
    "top_pop_sample = get_top_popular_videos(n=10, min_ratings=5)\n",
    "\n",
    "# --- Content-based ---\n",
    "content_df = videos.copy()\n",
    "content_df['specialities'] = (content_df['specialities'].fillna('')\n",
    "                              .str.lower().str.replace(r'[^\\w\\s|]', ' ', regex=True)\n",
    "                              .str.replace(r'\\|', ' ', regex=True)\n",
    "                              .str.replace(r'\\s+', ' ', regex=True).str.strip())\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "tfidf = vectorizer.fit_transform(content_df['specialities'])\n",
    "title_to_index = pd.Series(content_df.index, index=content_df['title'])\n",
    "\n",
    "def get_content_recs_by_title(title, n=10):\n",
    "    if title not in title_to_index:\n",
    "        return pd.DataFrame(columns=['video_id','title','score'])\n",
    "    idx = title_to_index[title]\n",
    "    sims = cosine_similarity(tfidf[idx], tfidf).ravel()\n",
    "    sims[idx] = -1  # exclude itself\n",
    "    top_idx = sims.argsort()[::-1][:n]\n",
    "    out = content_df.iloc[top_idx][['video_id','title']].copy()\n",
    "    out['score'] = sims[top_idx]\n",
    "    return out\n",
    "\n",
    "# Prepare a valid favorite title\n",
    "valid_fav_title = favs['favorite_title'].dropna()\n",
    "valid_fav_title = valid_fav_title[valid_fav_title.isin(videos['title'])]\n",
    "fav_title_example = valid_fav_title.sample(1, random_state=42).iloc[0] if len(valid_fav_title)>0 else None\n",
    "content_recs_sample = get_content_recs_by_title(fav_title_example, n=5) if fav_title_example else pd.DataFrame()\n",
    "\n",
    "# --- Collaborative Filtering ---\n",
    "# Try to import surprise; fallback to baseline if not available\n",
    "use_surprise = True\n",
    "try:\n",
    "    from surprise import Dataset, Reader, SVD\n",
    "    from surprise.model_selection import train_test_split\n",
    "    from surprise import accuracy\n",
    "except Exception as e:\n",
    "    use_surprise = False\n",
    "    surprise_error = str(e)\n",
    "\n",
    "def train_svd_model(ratings_df):\n",
    "    rdr = Reader(rating_scale=(ratings_df['rating_score'].min(), ratings_df['rating_score'].max()))\n",
    "    data = Dataset.load_from_df(ratings_df[['user_id','video_id','rating_score']], rdr)\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo = SVD(random_state=42)\n",
    "    algo.fit(trainset)\n",
    "    return algo, trainset\n",
    "\n",
    "def get_collab_recs_svd(user_id, n=10):\n",
    "    # Candidate set: all videos the user has not rated\n",
    "    if user_id not in rates['user_id'].unique():\n",
    "        return pd.DataFrame(columns=['video_id','title','score'])\n",
    "    # Build anti-testset\n",
    "    inner_uid = svd_trainset.to_inner_uid(user_id)\n",
    "    unseen_inner_iids = [i for i in svd_trainset.all_items()\n",
    "                         if svd_trainset.ur[inner_uid] is not None and i not in [j for (j, _) in svd_trainset.ur[inner_uid]]]\n",
    "    # If ur is empty (extreme case), recommend all\n",
    "    if len(unseen_inner_iids)==0:\n",
    "        unseen_inner_iids = list(svd_trainset.all_items())\n",
    "    preds = []\n",
    "    for inner_iid in unseen_inner_iids:\n",
    "        raw_iid = svd_trainset.to_raw_iid(inner_iid)\n",
    "        preds.append((raw_iid, svd_algo.predict(user_id, raw_iid).est))\n",
    "    recs = sorted(preds, key=lambda x: x[1], reverse=True)[:n]\n",
    "    out = pd.DataFrame({'video_id':[int(i) for i,_ in recs],'score':[s for _,s in recs]})\n",
    "    out = out.merge(videos[['video_id','title']], on='video_id', how='left')\n",
    "    return out\n",
    "\n",
    "# Baseline (if surprise not supported)\n",
    "global_mean = rates['rating_score'].mean()\n",
    "item_mean = rates.groupby('video_id')['rating_score'].mean()\n",
    "\n",
    "def get_collab_recs_baseline(user_id, n=10):\n",
    "    seen = set(rates.loc[rates['user_id']==user_id, 'video_id'].values)\n",
    "    candidates = item_mean[~item_mean.index.isin(seen)].sort_values(ascending=False).head(n)\n",
    "    out = pd.DataFrame({'video_id': candidates.index.astype(int), 'score': candidates.values})\n",
    "    out = out.merge(videos[['video_id','title']], on='video_id', how='left')\n",
    "    return out\n",
    "\n",
    "if use_surprise:\n",
    "    svd_algo, svd_trainset = train_svd_model(rates)\n",
    "    collab_recs_sample = get_collab_recs_svd(sample_user, n=5)\n",
    "else:\n",
    "    collab_recs_sample = get_collab_recs_baseline(sample_user, n=5)\n",
    "\n",
    "# --- Hybrid with fallback ---\n",
    "def minmax_normalize(s):\n",
    "    s = s.astype(float)\n",
    "    return (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
    "\n",
    "def hybrid_recommender(user_id, n=10, weights=(0.33, 0.33, 0.34)):\n",
    "    pw, cw, rw = weights\n",
    "    total = pw+cw+rw\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"Invalid weights.\")\n",
    "    pw, cw, rw = pw/total, cw/total, rw/total\n",
    "\n",
    "    # Popularity\n",
    "    pop_scores = video_stats[['video_id','avg_rating']].copy()\n",
    "    pop_scores['popularity_score'] = minmax_normalize(pop_scores['avg_rating'])\n",
    "    pop_scores = pop_scores[['video_id','popularity_score']]\n",
    "\n",
    "    # Collaborative\n",
    "    if user_id in rates['user_id'].unique():\n",
    "        if use_surprise:\n",
    "            collab = get_collab_recs_svd(user_id, n=len(videos)) # get as many candidates as possible\n",
    "        else:\n",
    "            collab = get_collab_recs_baseline(user_id, n=len(videos))\n",
    "        collab = collab[['video_id','score']].rename(columns={'score':'collab_score'})\n",
    "        collab['collab_score'] = minmax_normalize(collab['collab_score'])\n",
    "        has_history = True\n",
    "    else:\n",
    "        collab = pd.DataFrame(columns=['video_id','collab_score'])\n",
    "        has_history = False\n",
    "\n",
    "    # Content (use user favorites if available, otherwise empty)\n",
    "    fav_title = None\n",
    "    if user_id in favs['user_id'].values:\n",
    "        fav_title = favs.loc[favs['user_id']==user_id, 'favorite_title'].dropna()\n",
    "        fav_title = fav_title[fav_title.isin(videos['title'])]\n",
    "        fav_title = fav_title.iloc[0] if len(fav_title)>0 else None\n",
    "    if fav_title is not None:\n",
    "        cont = get_content_recs_by_title(fav_title, n=200)[['video_id','score']].rename(columns={'score':'content_score'})\n",
    "        cont['content_score'] = minmax_normalize(cont['content_score'])\n",
    "    else:\n",
    "        cont = pd.DataFrame(columns=['video_id','content_score'])\n",
    "\n",
    "    # Merge\n",
    "    base = videos[['video_id','title']].copy()\n",
    "    merged = (base\n",
    "              .merge(pop_scores, on='video_id', how='left')\n",
    "              .merge(collab, on='video_id', how='left')\n",
    "              .merge(cont, on='video_id', how='left'))\n",
    "    merged[['popularity_score','collab_score','content_score']] = merged[['popularity_score','collab_score','content_score']].fillna(0.0)\n",
    "\n",
    "    # Cold-start: use only Popularity\n",
    "    if not has_history:\n",
    "        merged['hybrid_score'] = merged['popularity_score']\n",
    "    else:\n",
    "        merged['hybrid_score'] = pw*merged['popularity_score'] + rw*merged['collab_score'] + cw*merged['content_score']\n",
    "\n",
    "    out = merged.sort_values('hybrid_score', ascending=False).head(n)\n",
    "    return out[['video_id','title','hybrid_score','popularity_score','collab_score','content_score']]\n",
    "\n",
    "hybrid_sample = hybrid_recommender(sample_user, n=5)\n",
    "\n",
    "# ------------- 1.3 Fault Case Analysis -------------\n",
    "\n",
    "# 1) Favorite title not found\n",
    "missing_favs = favs['favorite_title'].isna().sum() + (~favs['favorite_title'].isin(videos['title'])).sum()\n",
    "\n",
    "# 2) Cold-start users (no ratings)\n",
    "all_users_with_ratings = set(rates['user_id'].unique())\n",
    "all_users = set(favs['user_id']).union(set(behav['user_id'])).union(set(top10['user_id']))\n",
    "cold_start_users = sorted(list(all_users - all_users_with_ratings))\n",
    "cold_user_example = cold_start_users[0] if len(cold_start_users)>0 else None\n",
    "hybrid_cold = hybrid_recommender(cold_user_example, n=5) if cold_user_example else pd.DataFrame()\n",
    "\n",
    "# 3) Videos without ratings\n",
    "videos_without_ratings = set(videos['video_id']) - set(rates['video_id'])\n",
    "count_videos_without_ratings = len(videos_without_ratings)\n",
    "\n",
    "# 4) Extreme weights (1,0,0)\n",
    "hybrid_pop_only = hybrid_recommender(sample_user, n=5, weights=(1,0,0))\n",
    "hybrid_collab_only = hybrid_recommender(sample_user, n=5, weights=(0,0,1))\n",
    "hybrid_content_only = hybrid_recommender(sample_user, n=5, weights=(0,1,0))\n",
    "\n",
    "# 5) Popularity small-sample anomaly check: does Top50 contain videos with num_ratings=1\n",
    "pop_top50 = get_top_popular_videos(n=50, min_ratings=1)\n",
    "pop_top50_with_small_sample = pop_top50[pop_top50['num_ratings']==1]\n",
    "\n",
    "# Summarize key metrics\n",
    "functional_summary = {\n",
    "    \"missing_favorite_titles_or_not_found\": int(missing_favs),\n",
    "    \"cold_start_user_count\": len(cold_start_users),\n",
    "    \"cold_start_user_example\": cold_user_example,\n",
    "    \"videos_without_any_ratings\": int(count_videos_without_ratings),\n",
    "    \"pop_top50_small_sample_count\": int(pop_top50_with_small_sample.shape[0]),\n",
    "    \"surprise_available\": use_surprise\n",
    "}\n",
    "\n",
    "functional_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10c30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample - Popularity Top10 (min_ratings=5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>42505</td>\n",
       "      <td>Cardio Training Video #42505</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>20905</td>\n",
       "      <td>Weight Loss Training Video #20905</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>76102</td>\n",
       "      <td>Powerlifting Training Video #76102</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>82210</td>\n",
       "      <td>Pilates Training Video #82210</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>65804</td>\n",
       "      <td>Rehabilitation Training Video #65804</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4007</td>\n",
       "      <td>Flexibility Training Video #4007</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>4304</td>\n",
       "      <td>Pilates Training Video #4304</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>35805</td>\n",
       "      <td>Strength Training Training Video #35805</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>27009</td>\n",
       "      <td>Rehabilitation Training Video #27009</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3006</td>\n",
       "      <td>CrossFit Training Video #3006</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                    title  avg_rating  \\\n",
       "4244     42505             Cardio Training Video #42505    4.720000   \n",
       "2084     20905        Weight Loss Training Video #20905    4.460000   \n",
       "7601     76102       Powerlifting Training Video #76102    4.380000   \n",
       "8219     82210            Pilates Training Video #82210    4.380000   \n",
       "6573     65804     Rehabilitation Training Video #65804    4.340000   \n",
       "396       4007         Flexibility Training Video #4007    4.320000   \n",
       "423       4304             Pilates Training Video #4304    4.300000   \n",
       "3574     35805  Strength Training Training Video #35805    4.285714   \n",
       "2698     27009     Rehabilitation Training Video #27009    4.280000   \n",
       "295       3006            CrossFit Training Video #3006    4.260000   \n",
       "\n",
       "      num_ratings  \n",
       "4244            5  \n",
       "2084            5  \n",
       "7601            5  \n",
       "8219            5  \n",
       "6573            5  \n",
       "396             5  \n",
       "423             5  \n",
       "3574            7  \n",
       "2698            5  \n",
       "295             5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>70909</td>\n",
       "      <td>Yoga Training Video #70909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>30803</td>\n",
       "      <td>Yoga Training Video #30803</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>69302</td>\n",
       "      <td>Elderly Fitness Training Video #69302</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>20506</td>\n",
       "      <td>Yoga Training Video #20506</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>77405</td>\n",
       "      <td>Elderly Fitness Training Video #77405</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                  title  score\n",
       "7088     70909             Yoga Training Video #70909    1.0\n",
       "3072     30803             Yoga Training Video #30803    1.0\n",
       "6921     69302  Elderly Fitness Training Video #69302    1.0\n",
       "2045     20506             Yoga Training Video #20506    1.0\n",
       "7734     77405  Elderly Fitness Training Video #77405    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample - Collaborative Top5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73602</td>\n",
       "      <td>3.907086</td>\n",
       "      <td>Pilates Training Video #73602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66105</td>\n",
       "      <td>3.889024</td>\n",
       "      <td>Pilates Training Video #66105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52506</td>\n",
       "      <td>3.875605</td>\n",
       "      <td>Flexibility Training Video #52506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55003</td>\n",
       "      <td>3.866376</td>\n",
       "      <td>Flexibility Training Video #55003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91007</td>\n",
       "      <td>3.861769</td>\n",
       "      <td>Rehabilitation Training Video #91007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id     score                                 title\n",
       "0     73602  3.907086         Pilates Training Video #73602\n",
       "1     66105  3.889024         Pilates Training Video #66105\n",
       "2     52506  3.875605     Flexibility Training Video #52506\n",
       "3     55003  3.866376     Flexibility Training Video #55003\n",
       "4     91007  3.861769  Rehabilitation Training Video #91007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample - Hybrid Top5 (default weights)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>67407</td>\n",
       "      <td>Pilates Training Video #67407</td>\n",
       "      <td>0.845246</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>77710</td>\n",
       "      <td>Pilates Training Video #77710</td>\n",
       "      <td>0.783743</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.594014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>58608</td>\n",
       "      <td>Pilates Training Video #58608</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.635397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>24405</td>\n",
       "      <td>CrossFit Training Video #24405</td>\n",
       "      <td>0.764372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844232</td>\n",
       "      <td>0.446465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>32801</td>\n",
       "      <td>HIIT Training Video #32801</td>\n",
       "      <td>0.740035</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                           title  hybrid_score  \\\n",
       "6736     67407   Pilates Training Video #67407      0.845246   \n",
       "7769     77710   Pilates Training Video #77710      0.783743   \n",
       "5857     58608   Pilates Training Video #58608      0.780702   \n",
       "2434     24405  CrossFit Training Video #24405      0.764372   \n",
       "3270     32801      HIIT Training Video #32801      0.740035   \n",
       "\n",
       "      popularity_score  collab_score  content_score  \n",
       "6736          0.822222      0.717391       1.000000  \n",
       "7769          0.762963      0.594014       1.000000  \n",
       "5857          0.711111      0.635397       1.000000  \n",
       "2434          1.000000      0.844232       0.446465  \n",
       "3270          0.711111      0.515789       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4207</td>\n",
       "      <td>CrossFit Training Video #4207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>76305</td>\n",
       "      <td>Prenatal Fitness Training Video #76305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>67309</td>\n",
       "      <td>Rehabilitation Training Video #67309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>76704</td>\n",
       "      <td>Prenatal Fitness Training Video #76704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>67005</td>\n",
       "      <td>Powerlifting Training Video #67005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                   title  hybrid_score  \\\n",
       "416       4207           CrossFit Training Video #4207           1.0   \n",
       "7624     76305  Prenatal Fitness Training Video #76305           1.0   \n",
       "6728     67309    Rehabilitation Training Video #67309           1.0   \n",
       "7663     76704  Prenatal Fitness Training Video #76704           1.0   \n",
       "6694     67005      Powerlifting Training Video #67005           1.0   \n",
       "\n",
       "      popularity_score  collab_score  content_score  \n",
       "416                1.0           0.0            0.0  \n",
       "7624               1.0           0.0            0.0  \n",
       "6728               1.0           0.0            0.0  \n",
       "7663               1.0           0.0            0.0  \n",
       "6694               1.0           0.0            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>609</td>\n",
       "      <td>CrossFit Training Video #609</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1103</td>\n",
       "      <td>Sports-Specific Training Video #1103</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1901</td>\n",
       "      <td>Yoga Training Video #1901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3109</td>\n",
       "      <td>Prenatal Fitness Training Video #3109</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4008</td>\n",
       "      <td>Flexibility Training Video #4008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4207</td>\n",
       "      <td>CrossFit Training Video #4207</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4308</td>\n",
       "      <td>Elderly Fitness Training Video #4308</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>5002</td>\n",
       "      <td>CrossFit Training Video #5002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>5504</td>\n",
       "      <td>Rehabilitation Training Video #5504</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>5606</td>\n",
       "      <td>Functional Training Training Video #5606</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>5610</td>\n",
       "      <td>CrossFit Training Video #5610</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>5807</td>\n",
       "      <td>Powerlifting Training Video #5807</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>6503</td>\n",
       "      <td>Powerlifting Training Video #6503</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>7207</td>\n",
       "      <td>Bodybuilding Training Video #7207</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7607</td>\n",
       "      <td>Functional Training Training Video #7607</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>8805</td>\n",
       "      <td>Yoga Training Video #8805</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>10807</td>\n",
       "      <td>Rehabilitation Training Video #10807</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>10905</td>\n",
       "      <td>Pilates Training Video #10905</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>11308</td>\n",
       "      <td>Functional Training Training Video #11308</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>11607</td>\n",
       "      <td>Sports-Specific Training Video #11607</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>11803</td>\n",
       "      <td>CrossFit Training Video #11803</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>12302</td>\n",
       "      <td>Weight Loss Training Video #12302</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>12406</td>\n",
       "      <td>Elderly Fitness Training Video #12406</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>13306</td>\n",
       "      <td>Functional Training Training Video #13306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>13510</td>\n",
       "      <td>Rehabilitation Training Video #13510</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>13603</td>\n",
       "      <td>Prenatal Fitness Training Video #13603</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>14010</td>\n",
       "      <td>Pilates Training Video #14010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>14306</td>\n",
       "      <td>Flexibility Training Video #14306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>15406</td>\n",
       "      <td>Muscle Building Training Video #15406</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>16307</td>\n",
       "      <td>Elderly Fitness Training Video #16307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>16806</td>\n",
       "      <td>CrossFit Training Video #16806</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>17105</td>\n",
       "      <td>Weight Loss Training Video #17105</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>19009</td>\n",
       "      <td>Sports-Specific Training Video #19009</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>24306</td>\n",
       "      <td>Strength Training Training Video #24306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>24405</td>\n",
       "      <td>CrossFit Training Video #24405</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>24805</td>\n",
       "      <td>Cardio Training Video #24805</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                      title  avg_rating  \\\n",
       "58         609               CrossFit Training Video #609         5.0   \n",
       "102       1103       Sports-Specific Training Video #1103         5.0   \n",
       "180       1901                  Yoga Training Video #1901         5.0   \n",
       "308       3109      Prenatal Fitness Training Video #3109         5.0   \n",
       "397       4008           Flexibility Training Video #4008         5.0   \n",
       "416       4207              CrossFit Training Video #4207         5.0   \n",
       "427       4308       Elderly Fitness Training Video #4308         5.0   \n",
       "491       5002              CrossFit Training Video #5002         5.0   \n",
       "543       5504        Rehabilitation Training Video #5504         5.0   \n",
       "555       5606   Functional Training Training Video #5606         5.0   \n",
       "559       5610              CrossFit Training Video #5610         5.0   \n",
       "576       5807          Powerlifting Training Video #5807         5.0   \n",
       "642       6503          Powerlifting Training Video #6503         5.0   \n",
       "716       7207          Bodybuilding Training Video #7207         5.0   \n",
       "756       7607   Functional Training Training Video #7607         5.0   \n",
       "874       8805                  Yoga Training Video #8805         5.0   \n",
       "1076     10807       Rehabilitation Training Video #10807         5.0   \n",
       "1084     10905              Pilates Training Video #10905         5.0   \n",
       "1127     11308  Functional Training Training Video #11308         5.0   \n",
       "1156     11607      Sports-Specific Training Video #11607         5.0   \n",
       "1172     11803             CrossFit Training Video #11803         5.0   \n",
       "1221     12302          Weight Loss Training Video #12302         5.0   \n",
       "1235     12406      Elderly Fitness Training Video #12406         5.0   \n",
       "1325     13306  Functional Training Training Video #13306         5.0   \n",
       "1349     13510       Rehabilitation Training Video #13510         5.0   \n",
       "1352     13603     Prenatal Fitness Training Video #13603         5.0   \n",
       "1399     14010              Pilates Training Video #14010         5.0   \n",
       "1425     14306          Flexibility Training Video #14306         5.0   \n",
       "1535     15406      Muscle Building Training Video #15406         5.0   \n",
       "1626     16307      Elderly Fitness Training Video #16307         5.0   \n",
       "1675     16806             CrossFit Training Video #16806         5.0   \n",
       "1704     17105          Weight Loss Training Video #17105         5.0   \n",
       "1898     19009      Sports-Specific Training Video #19009         5.0   \n",
       "2425     24306    Strength Training Training Video #24306         5.0   \n",
       "2434     24405             CrossFit Training Video #24405         5.0   \n",
       "2474     24805               Cardio Training Video #24805         5.0   \n",
       "\n",
       "      num_ratings  \n",
       "58              1  \n",
       "102             1  \n",
       "180             1  \n",
       "308             1  \n",
       "397             1  \n",
       "416             1  \n",
       "427             1  \n",
       "491             1  \n",
       "543             1  \n",
       "555             1  \n",
       "559             1  \n",
       "576             1  \n",
       "642             1  \n",
       "716             1  \n",
       "756             1  \n",
       "874             1  \n",
       "1076            1  \n",
       "1084            1  \n",
       "1127            1  \n",
       "1156            1  \n",
       "1172            1  \n",
       "1221            1  \n",
       "1235            1  \n",
       "1325            1  \n",
       "1349            1  \n",
       "1352            1  \n",
       "1399            1  \n",
       "1425            1  \n",
       "1535            1  \n",
       "1626            1  \n",
       "1675            1  \n",
       "1704            1  \n",
       "1898            1  \n",
       "2425            1  \n",
       "2434            1  \n",
       "2474            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display key sample tables\n",
    "print(\"Sample - Popularity Top10 (min_ratings=5)\")\n",
    "display(top_pop_sample)\n",
    "if fav_title_example:\n",
    "    display(content_recs_sample)\n",
    "print(\"Sample - Collaborative Top5\")\n",
    "display(collab_recs_sample)\n",
    "print(\"Sample - Hybrid Top5 (default weights)\")\n",
    "display(hybrid_sample)\n",
    "\n",
    "if not hybrid_cold.empty:\n",
    "    display(hybrid_cold)\n",
    "\n",
    "if not pop_top50_with_small_sample.empty:\n",
    "    display(pop_top50_with_small_sample)\n",
    "\n",
    "# Extra diagnostic: number of duplicate titles\n",
    "dup_title_count = videos['title'].duplicated().sum()\n",
    "dup_title_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0639966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Top5 - Popularity only (1,0,0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4207</td>\n",
       "      <td>CrossFit Training Video #4207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663644</td>\n",
       "      <td>0.423923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>76305</td>\n",
       "      <td>Prenatal Fitness Training Video #76305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738615</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>67309</td>\n",
       "      <td>Rehabilitation Training Video #67309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.746554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>76704</td>\n",
       "      <td>Prenatal Fitness Training Video #76704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.656218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>67005</td>\n",
       "      <td>Powerlifting Training Video #67005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                   title  hybrid_score  \\\n",
       "416       4207           CrossFit Training Video #4207           1.0   \n",
       "7624     76305  Prenatal Fitness Training Video #76305           1.0   \n",
       "6728     67309    Rehabilitation Training Video #67309           1.0   \n",
       "7663     76704  Prenatal Fitness Training Video #76704           1.0   \n",
       "6694     67005      Powerlifting Training Video #67005           1.0   \n",
       "\n",
       "      popularity_score  collab_score  content_score  \n",
       "416                1.0      0.663644       0.423923  \n",
       "7624               1.0      0.738615       0.000000  \n",
       "6728               1.0      0.746554       0.000000  \n",
       "7663               1.0      0.656218       0.000000  \n",
       "6694               1.0      0.572582       0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Top5 - Collaborative only (0,0,1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>73602</td>\n",
       "      <td>Pilates Training Video #73602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>66105</td>\n",
       "      <td>Pilates Training Video #66105</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>52506</td>\n",
       "      <td>Flexibility Training Video #52506</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.971811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>55003</td>\n",
       "      <td>Flexibility Training Video #55003</td>\n",
       "      <td>0.963548</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.963548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>91007</td>\n",
       "      <td>Rehabilitation Training Video #91007</td>\n",
       "      <td>0.959422</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.959422</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                 title  hybrid_score  \\\n",
       "7351     73602         Pilates Training Video #73602      1.000000   \n",
       "6604     66105         Pilates Training Video #66105      0.983827   \n",
       "5245     52506     Flexibility Training Video #52506      0.971811   \n",
       "5492     55003     Flexibility Training Video #55003      0.963548   \n",
       "9096     91007  Rehabilitation Training Video #91007      0.959422   \n",
       "\n",
       "      popularity_score  collab_score  content_score  \n",
       "7351          0.933333      1.000000            0.0  \n",
       "6604          0.927778      0.983827            0.0  \n",
       "5245          0.900000      0.971811            0.0  \n",
       "5492          0.804444      0.963548            0.0  \n",
       "9096          0.896296      0.959422            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Top5 - Content only (0,1,0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>67407</td>\n",
       "      <td>Pilates Training Video #67407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>31504</td>\n",
       "      <td>HIIT Training Video #31504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>77710</td>\n",
       "      <td>Pilates Training Video #77710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.594014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>12706</td>\n",
       "      <td>CrossFit Training Video #12706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.557014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>33704</td>\n",
       "      <td>CrossFit Training Video #33704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                           title  hybrid_score  \\\n",
       "6736     67407   Pilates Training Video #67407           1.0   \n",
       "3143     31504      HIIT Training Video #31504           1.0   \n",
       "7769     77710   Pilates Training Video #77710           1.0   \n",
       "1265     12706  CrossFit Training Video #12706           1.0   \n",
       "3363     33704  CrossFit Training Video #33704           1.0   \n",
       "\n",
       "      popularity_score  collab_score  content_score  \n",
       "6736          0.822222      0.717391            1.0  \n",
       "3143          0.000000      0.000000            1.0  \n",
       "7769          0.762963      0.594014            1.0  \n",
       "1265          0.666667      0.557014            1.0  \n",
       "3363          0.000000      0.000000            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content_based_excludes_self': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-exclusion check (Content-based)\n",
    "if fav_title_example:\n",
    "    contains_self = (content_recs_sample['title'] == fav_title_example).any()\n",
    "else:\n",
    "    contains_self = False\n",
    "\n",
    "# Display extreme weight results\n",
    "print(\"Hybrid Top5 - Popularity only (1,0,0)\")\n",
    "display(hybrid_pop_only)\n",
    "print(\"Hybrid Top5 - Collaborative only (0,0,1)\")\n",
    "display(hybrid_collab_only)\n",
    "print(\"Hybrid Top5 - Content only (0,1,0)\")\n",
    "display(hybrid_content_only)\n",
    "\n",
    "{\"content_based_excludes_self\": (not contains_self)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bc3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "      <th>hybrid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9824</th>\n",
       "      <td>98305</td>\n",
       "      <td>Powerlifting Training Video #98305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                               title  popularity_score  \\\n",
       "9824     98305  Powerlifting Training Video #98305               0.0   \n",
       "\n",
       "      collab_score  content_score  hybrid_score  \n",
       "9824           0.0            0.0           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targeted diagnosis of whether videos without ratings affect fusion: Output the complete rating table for the specified user, then observe the three scores for a video without a rating.\n",
    "def hybrid_scores_full(user_id, weights=(0.33,0.33,0.34)):\n",
    "    pw, cw, rw = weights\n",
    "    total = pw+cw+rw\n",
    "    pw, cw, rw = pw/total, cw/total, rw/total\n",
    "\n",
    "    # Popularity\n",
    "    pop_scores = video_stats[['video_id','avg_rating']].copy()\n",
    "    pop_scores['popularity_score'] = minmax_normalize(pop_scores['avg_rating'])\n",
    "    pop_scores = pop_scores[['video_id','popularity_score']]\n",
    "\n",
    "    # Collaborative\n",
    "    if user_id in rates['user_id'].unique():\n",
    "        if use_surprise:\n",
    "            collab = get_collab_recs_svd(user_id, n=len(videos))\n",
    "        else:\n",
    "            collab = get_collab_recs_baseline(user_id, n=len(videos))\n",
    "        collab = collab[['video_id','score']].rename(columns={'score':'collab_score'})\n",
    "        collab['collab_score'] = minmax_normalize(collab['collab_score'])\n",
    "        has_history = True\n",
    "    else:\n",
    "        collab = pd.DataFrame(columns=['video_id','collab_score'])\n",
    "        has_history = False\n",
    "\n",
    "    # Content\n",
    "    fav_title = None\n",
    "    if user_id in favs['user_id'].values:\n",
    "        fav_title = favs.loc[favs['user_id']==user_id, 'favorite_title'].dropna()\n",
    "        fav_title = fav_title[fav_title.isin(videos['title'])]\n",
    "        fav_title = fav_title.iloc[0] if len(fav_title)>0 else None\n",
    "    if fav_title is not None:\n",
    "        cont = get_content_recs_by_title(fav_title, n=200)[['video_id','score']].rename(columns={'score':'content_score'})\n",
    "        cont['content_score'] = minmax_normalize(cont['content_score'])\n",
    "    else:\n",
    "        cont = pd.DataFrame(columns=['video_id','content_score'])\n",
    "\n",
    "    base = videos[['video_id','title']].copy()\n",
    "    merged = (base\n",
    "              .merge(pop_scores, on='video_id', how='left')\n",
    "              .merge(collab, on='video_id', how='left')\n",
    "              .merge(cont, on='video_id', how='left'))\n",
    "    merged[['popularity_score','collab_score','content_score']] = merged[['popularity_score','collab_score','content_score']].fillna(0.0)\n",
    "    if not has_history:\n",
    "        merged['hybrid_score'] = merged['popularity_score']\n",
    "    else:\n",
    "        merged['hybrid_score'] = pw*merged['popularity_score'] + rw*merged['collab_score'] + cw*merged['content_score']\n",
    "    return merged\n",
    "\n",
    "no_rate_video = next(iter(videos_without_ratings)) if len(videos_without_ratings)>0 else None\n",
    "scores_df = hybrid_scores_full(sample_user)\n",
    "row_no_rate = scores_df[scores_df['video_id']==no_rate_video]\n",
    "\n",
    "row_no_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75b9ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_fav_example': [{'user_id': 'U0013', 'favorite_title': nan}],\n",
       " 'content_rec_rows_returned': 0,\n",
       " 'error_when_missing': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a collection title that does not exist in videos (or is missing) for testing.\n",
    "missing_fav_rows = favs[(favs['favorite_title'].isna()) | (~favs['favorite_title'].isin(videos['title']))]\n",
    "missing_fav_example = missing_fav_rows.head(1)\n",
    "missing_title = None if missing_fav_example.empty else missing_fav_example['favorite_title'].iloc[0]\n",
    "user_with_missing_fav = None if missing_fav_example.empty else missing_fav_example['user_id'].iloc[0]\n",
    "\n",
    "# Run content recall for users with missing collections (should return an empty table, no error reported)\n",
    "content_missing_case = get_content_recs_by_title(missing_title, n=5) if missing_title is not None else pd.DataFrame()\n",
    "\n",
    "{\n",
    "    \"missing_fav_example\": None if missing_fav_example.empty else missing_fav_example.to_dict(orient=\"records\"),\n",
    "    \"content_rec_rows_returned\": 0 if content_missing_case is None or content_missing_case.empty else content_missing_case.shape[0],\n",
    "    \"error_when_missing\": False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a682f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'videos.video_id_duplicated': 0,\n",
       " 'rates.user_video_duplicated': 0,\n",
       " 'favs.user_duplicated': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "duplicates_report = {\n",
    "    \"videos.video_id_duplicated\": int(videos['video_id'].duplicated().sum()),\n",
    "    \"rates.user_video_duplicated\": int(rates.duplicated(subset=['user_id','video_id']).sum()),\n",
    "    \"favs.user_duplicated\": int(favs['user_id'].duplicated().sum())\n",
    "}\n",
    "duplicates_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600375e",
   "metadata": {},
   "source": [
    "# Behavioral Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e94f26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\133472278.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_div = rec_with_tags.groupby('user_id').apply(user_diversity).reset_index()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\133472278.py:82: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_ctr = rec_clicked.groupby('user_id').apply(lambda x: (x['_merge']=='both').mean()).rename('ctr').reset_index()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\133472278.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_watch = rec_watched.groupby('user_id').apply(lambda x: (x['_merge']=='both').mean()).rename('watch_rate').reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'catalog_size': 10000,\n",
       "  'rec_video_coverage': 0.3974,\n",
       "  'global_tag_entropy': 2.7296749196215493,\n",
       "  'avg_unique_tags_per_user_top10': 9.779220779220779,\n",
       "  'avg_intra_list_jaccard': 0.3879594479594479,\n",
       "  'overall_ctr': 0.005394605394605395,\n",
       "  'overall_watch_rate': 0.2519968051118211,\n",
       "  'cold_users_count': 1,\n",
       "  'non_cold_users_count': 1000},\n",
       "    pop_decile  count  ratio\n",
       " 0           0   1001    0.1\n",
       " 1           1   1001    0.1\n",
       " 2           2   1001    0.1\n",
       " 3           3   1001    0.1\n",
       " 4           4   1001    0.1,\n",
       "             cohort  size       ctr  watch_rate\n",
       " 0       cold_users     1  0.000000    0.200000\n",
       " 1   non_cold_users  1000  0.005400    0.251991\n",
       " 2  high_freq_users   336  0.006548    0.253869\n",
       " 3   low_freq_users   664  0.004819    0.251041,\n",
       " {'pop>0_ratio': 1.0, 'collab>0_ratio': 0.0, 'content>0_ratio': 0.0},\n",
       " {'pop>0_ratio': 0.3931, 'collab>0_ratio': 0.4609, 'content>0_ratio': 0.5266})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# ---------- Load data ----------\n",
    "file_path = \"Hybrid_Reco_Videos_Data.xlsx\"\n",
    "videos = pd.read_excel(file_path, sheet_name=\"videos' info\")\n",
    "rates = pd.read_excel(file_path, sheet_name=\"filtered_rate_data\")\n",
    "recs = pd.read_excel(file_path, sheet_name=\"all_users_top10_recommendations\")\n",
    "behav = pd.read_excel(file_path, sheet_name=\"User behavior\")\n",
    "\n",
    "# Helper: split video tags\n",
    "def split_tags(s):\n",
    "    if pd.isna(s): \n",
    "        return []\n",
    "    return [t.strip().lower() for t in str(s).split('|') if t.strip()]\n",
    "\n",
    "videos['tags'] = videos['specialities'].apply(split_tags)\n",
    "\n",
    "# ------------- 2.2 System Output Analysis -------------\n",
    "# A) Top-N recommendation quality\n",
    "# 1) Catalog coverage\n",
    "catalog_size = videos['video_id'].nunique()\n",
    "rec_videos = recs['video_id'].nunique()\n",
    "catalog_coverage = rec_videos / catalog_size\n",
    "\n",
    "# 2) Popularity distribution (by decile of popularity_score)\n",
    "# popularity_score is already provided in recs (0-1). Divide into 10 deciles\n",
    "recs['pop_decile'] = pd.qcut(recs['popularity_score'].rank(method='first'), 10, labels=False)\n",
    "pop_distribution = recs.groupby('pop_decile').size().rename('count').reset_index()\n",
    "pop_distribution['ratio'] = pop_distribution['count'] / len(recs)\n",
    "\n",
    "# 3) Diversity (tag distribution/entropy, avg. unique tags per user Top10)\n",
    "rec_with_tags = recs.merge(videos[['video_id','tags']], on='video_id', how='left')\n",
    "# 3.1 Global tag distribution entropy\n",
    "all_tags = [tag for tags in rec_with_tags['tags'] for tag in tags]\n",
    "tag_counts = Counter(all_tags)\n",
    "tag_probs = np.array(list(tag_counts.values()), dtype=float)\n",
    "tag_probs = tag_probs / tag_probs.sum() if tag_probs.sum()>0 else tag_probs\n",
    "global_tag_entropy = -(tag_probs * np.log(tag_probs + 1e-12)).sum()\n",
    "\n",
    "# 3.2 User-level diversity: unique tags in Top10 & avg. Jaccard similarity (lower = more diverse)\n",
    "def user_diversity(df):\n",
    "    tags_list = df['tags'].tolist()\n",
    "    uniq_tags = set()\n",
    "    for ts in tags_list:\n",
    "        uniq_tags |= set(ts)\n",
    "    # Compute avg. Jaccard similarity (based on tags)\n",
    "    sims = []\n",
    "    for i in range(len(tags_list)):\n",
    "        for j in range(i+1, len(tags_list)):\n",
    "            a, b = set(tags_list[i]), set(tags_list[j])\n",
    "            if len(a)==0 and len(b)==0:\n",
    "                sims.append(1.0)\n",
    "            else:\n",
    "                sims.append(len(a & b) / (len(a | b)) if len(a | b)>0 else 0.0)\n",
    "    avg_jaccard = float(np.mean(sims)) if sims else np.nan\n",
    "    return pd.Series({'unique_tags': len(uniq_tags), 'avg_jaccard': avg_jaccard})\n",
    "\n",
    "user_div = rec_with_tags.groupby('user_id').apply(user_diversity).reset_index()\n",
    "avg_unique_tags = user_div['unique_tags'].mean()\n",
    "avg_jaccard = user_div['avg_jaccard'].mean()\n",
    "\n",
    "# B) Compare with user behavior (CTR / Watch rate)\n",
    "# Align recommendation results with behavior logs by user_id, video_id\n",
    "behav_click = behav[behav['action_type']=='click']\n",
    "behav_watch = behav[behav['action_type']=='watch']\n",
    "\n",
    "rec_key = recs[['user_id','video_id']].copy()\n",
    "rec_key['recommended'] = 1\n",
    "\n",
    "# CTR (recommendation → click)\n",
    "rec_clicked = rec_key.merge(behav_click, on=['user_id','video_id'], how='left', indicator=True)\n",
    "ctr = (rec_clicked['_merge']=='both').mean()\n",
    "\n",
    "# Watch rate (recommendation → watch)\n",
    "rec_watched = rec_key.merge(behav_watch, on=['user_id','video_id'], how='left', indicator=True)\n",
    "watch_rate = (rec_watched['_merge']=='both').mean()\n",
    "\n",
    "# User-level CTR / Watch rate\n",
    "user_ctr = rec_clicked.groupby('user_id').apply(lambda x: (x['_merge']=='both').mean()).rename('ctr').reset_index()\n",
    "user_watch = rec_watched.groupby('user_id').apply(lambda x: (x['_merge']=='both').mean()).rename('watch_rate').reset_index()\n",
    "user_behav_metrics = user_ctr.merge(user_watch, on='user_id', how='outer').fillna(0.0)\n",
    "\n",
    "# C) Performance across user cohorts\n",
    "users_with_ratings = set(rates['user_id'].unique())\n",
    "users_in_recs = set(recs['user_id'].unique())\n",
    "cold_users = sorted(list(users_in_recs - users_with_ratings))\n",
    "non_cold_users = sorted(list(users_in_recs & users_with_ratings))\n",
    "\n",
    "# High-freq / low-freq: based on rating count quantile\n",
    "user_rate_counts = rates.groupby('user_id').size().rename('rate_cnt')\n",
    "if not user_rate_counts.empty:\n",
    "    thr = user_rate_counts.quantile(0.67)\n",
    "    high_users = set(user_rate_counts[user_rate_counts>=thr].index)\n",
    "    low_users = set(user_rate_counts[user_rate_counts<thr].index)\n",
    "else:\n",
    "    high_users, low_users = set(), set()\n",
    "\n",
    "# Assign CTR / Watch rate to cohorts\n",
    "def cohort_metrics(user_list, name):\n",
    "    if not user_list:\n",
    "        return {'cohort': name, 'size': 0, 'ctr': np.nan, 'watch_rate': np.nan}\n",
    "    df = user_behav_metrics[user_behav_metrics['user_id'].isin(user_list)]\n",
    "    return {'cohort': name, 'size': int(len(df)), 'ctr': float(df['ctr'].mean()), 'watch_rate': float(df['watch_rate'].mean())}\n",
    "\n",
    "cohorts = []\n",
    "cohorts.append(cohort_metrics(cold_users, 'cold_users'))\n",
    "cohorts.append(cohort_metrics(non_cold_users, 'non_cold_users'))\n",
    "cohorts.append(cohort_metrics(list(high_users & set(non_cold_users)), 'high_freq_users'))\n",
    "cohorts.append(cohort_metrics(list(low_users & set(non_cold_users)), 'low_freq_users'))\n",
    "cohort_df = pd.DataFrame(cohorts)\n",
    "\n",
    "# D) Cold-start performance: contribution share from Popularity / CF / Content\n",
    "# Basis: in recs, check if each score > 0\n",
    "def source_share(df):\n",
    "    n = len(df)\n",
    "    pop = (df['popularity_score']>0).mean() if n>0 else np.nan\n",
    "    col = (df['collab_score']>0).mean() if n>0 else np.nan\n",
    "    cnt = (df['content_score']>0).mean() if n>0 else np.nan\n",
    "    return pd.Series({'pop>0_ratio':pop,'collab>0_ratio':col,'content>0_ratio':cnt})\n",
    "\n",
    "cold_source = recs[recs['user_id'].isin(cold_users)].pipe(source_share)\n",
    "noncold_source = recs[recs['user_id'].isin(non_cold_users)].pipe(source_share)\n",
    "\n",
    "# Summary results\n",
    "behavior_summary = {\n",
    "    \"catalog_size\": int(catalog_size),\n",
    "    \"rec_video_coverage\": float(catalog_coverage),\n",
    "    \"global_tag_entropy\": float(global_tag_entropy),\n",
    "    \"avg_unique_tags_per_user_top10\": float(avg_unique_tags),\n",
    "    \"avg_intra_list_jaccard\": float(avg_jaccard),\n",
    "    \"overall_ctr\": float(ctr),\n",
    "    \"overall_watch_rate\": float(watch_rate),\n",
    "    \"cold_users_count\": int(len(cold_users)),\n",
    "    \"non_cold_users_count\": int(len(non_cold_users)),\n",
    "}\n",
    "\n",
    "behavior_summary, pop_distribution.head(), cohort_df, cold_source.to_dict(), noncold_source.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5a4f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity decile distribution in Top-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_decile</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pop_decile  count  ratio\n",
       "0           0   1001    0.1\n",
       "1           1   1001    0.1\n",
       "2           2   1001    0.1\n",
       "3           3   1001    0.1\n",
       "4           4   1001    0.1\n",
       "5           5   1001    0.1\n",
       "6           6   1001    0.1\n",
       "7           7   1001    0.1\n",
       "8           8   1001    0.1\n",
       "9           9   1001    0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-level CTR & WatchRate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ctr</th>\n",
       "      <th>watch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>U0996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>U0997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>U0998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>U0999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>U1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  ctr  watch_rate\n",
       "0      U0000  0.0         0.2\n",
       "1      U0001  0.0         0.3\n",
       "2      U0002  0.0         0.3\n",
       "3      U0003  0.0         0.3\n",
       "4      U0004  0.0         0.3\n",
       "...      ...  ...         ...\n",
       "996    U0996  0.0         0.2\n",
       "997    U0997  0.0         0.3\n",
       "998    U0998  0.0         0.3\n",
       "999    U0999  0.0         0.3\n",
       "1000   U1000  0.0         0.2\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>size</th>\n",
       "      <th>ctr</th>\n",
       "      <th>watch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cold_users</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_cold_users</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.251991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_freq_users</td>\n",
       "      <td>336</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.253869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low_freq_users</td>\n",
       "      <td>664</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.251041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cohort  size       ctr  watch_rate\n",
       "0       cold_users     1  0.000000    0.200000\n",
       "1   non_cold_users  1000  0.005400    0.251991\n",
       "2  high_freq_users   336  0.006548    0.253869\n",
       "3   low_freq_users   664  0.004819    0.251041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\2238361881.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_tag_cov = rec_with_tags.groupby('user_id').apply(per_user_tag_coverage).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Per-user Top-10 unique tag counts'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>unique_tags_in_top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0002</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0003</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0004</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>U0996</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>U0997</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>U0998</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>U0999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>U1000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  unique_tags_in_top10\n",
       "0      U0000                    12\n",
       "1      U0001                    10\n",
       "2      U0002                    12\n",
       "3      U0003                     9\n",
       "4      U0004                     4\n",
       "...      ...                   ...\n",
       "996    U0996                     8\n",
       "997    U0997                    13\n",
       "998    U0998                     6\n",
       "999    U0999                    10\n",
       "1000   U1000                    14\n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cold-start user U1000 - score composition'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>video_id</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>content_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1</td>\n",
       "      <td>42505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>2</td>\n",
       "      <td>20905</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>3</td>\n",
       "      <td>76102</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>4</td>\n",
       "      <td>82210</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>5</td>\n",
       "      <td>65804</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>6</td>\n",
       "      <td>4007</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>7</td>\n",
       "      <td>4304</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>8</td>\n",
       "      <td>35805</td>\n",
       "      <td>0.565714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>9</td>\n",
       "      <td>27009</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>10</td>\n",
       "      <td>3006</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank  video_id  popularity_score  collab_score  content_score\n",
       "910     1     42505          1.000000           0.0            0.0\n",
       "911     2     20905          0.740000           0.0            0.0\n",
       "912     3     76102          0.660000           0.0            0.0\n",
       "913     4     82210          0.660000           0.0            0.0\n",
       "914     5     65804          0.620000           0.0            0.0\n",
       "915     6      4007          0.600000           0.0            0.0\n",
       "916     7      4304          0.580000           0.0            0.0\n",
       "917     8     35805          0.565714           0.0            0.0\n",
       "918     9     27009          0.560000           0.0            0.0\n",
       "919    10      3006          0.540000           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output distribution tables and user-level behavior metrics for inspection\n",
    "print(\"Popularity decile distribution in Top-10\")\n",
    "display(pop_distribution)\n",
    "print(\"User-level CTR & WatchRate\")\n",
    "display(user_behav_metrics)\n",
    "print(\"Cohort metrics\")\n",
    "display(cohort_df)\n",
    "\n",
    "# Compute per-user Top-10 tag coverage/diversity\n",
    "def per_user_tag_coverage(df):\n",
    "    tag_set = set([t for tags in df['tags'] for t in tags])\n",
    "    return pd.Series({'unique_tags_in_top10': len(tag_set)})\n",
    "\n",
    "user_tag_cov = rec_with_tags.groupby('user_id').apply(per_user_tag_coverage).reset_index()\n",
    "display(\"Per-user Top-10 unique tag counts\", user_tag_cov)\n",
    "\n",
    "# Verify cold-start user recommendation list source\n",
    "if len(cold_users)>0:\n",
    "    cold_example = cold_users[0]\n",
    "    cold_list = recs[recs['user_id']==cold_example][['rank','video_id','popularity_score','collab_score','content_score']].copy()\n",
    "    display(f\"Cold-start user {cold_example} - score composition\", cold_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e078cd7",
   "metadata": {},
   "source": [
    "# Decision Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5f2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\2028855098.py:176: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_div_df = recs_df.groupby('user_id').apply(user_div).reset_index()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\2028855098.py:176: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_div_df = recs_df.groupby('user_id').apply(user_div).reset_index()\n",
      "C:\\Users\\97059\\AppData\\Local\\Temp\\ipykernel_44456\\2028855098.py:176: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_div_df = recs_df.groupby('user_id').apply(user_div).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>coverage</th>\n",
       "      <th>global_tag_entropy</th>\n",
       "      <th>avg_unique_tags_per_user</th>\n",
       "      <th>avg_intra_list_jaccard</th>\n",
       "      <th>ctr</th>\n",
       "      <th>watch_rate</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hybrid</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>2.729675</td>\n",
       "      <td>9.779221</td>\n",
       "      <td>0.387959</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.251997</td>\n",
       "      <td>10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserCF</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>2.771416</td>\n",
       "      <td>13.095000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ItemCF</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>2.771716</td>\n",
       "      <td>13.079000</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  coverage  global_tag_entropy  avg_unique_tags_per_user  \\\n",
       "0  Hybrid    0.3974            2.729675                  9.779221   \n",
       "1  UserCF    0.3445            2.771416                 13.095000   \n",
       "2  ItemCF    0.3953            2.771716                 13.079000   \n",
       "\n",
       "   avg_intra_list_jaccard       ctr  watch_rate   rows  \n",
       "0                0.387959  0.005395    0.251997  10010  \n",
       "1                0.100000  0.006100    0.003200  10000  \n",
       "2                0.101075  0.006000    0.001400  10000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# ---------- Load data ----------\n",
    "file_path = \"Hybrid_Reco_Videos_Data.xlsx\"\n",
    "videos = pd.read_excel(file_path, sheet_name=\"videos' info\")\n",
    "rates = pd.read_excel(file_path, sheet_name=\"filtered_rate_data\")\n",
    "recs_hybrid = pd.read_excel(file_path, sheet_name=\"all_users_top10_recommendations\")\n",
    "behav = pd.read_excel(file_path, sheet_name=\"User behavior\")\n",
    "\n",
    "# ---------- Prepare lookups ----------\n",
    "users = sorted(rates['user_id'].unique())\n",
    "items = sorted(rates['video_id'].unique())\n",
    "uid2idx = {u:i for i,u in enumerate(users)}\n",
    "iid2idx = {i:j for j,i in enumerate(items)}\n",
    "idx2uid = {i:u for u,i in uid2idx.items()}\n",
    "idx2iid = {j:i for i,j in iid2idx.items()}\n",
    "\n",
    "# user set to evaluate: use same users as hybrid recommendations (for fair compare)\n",
    "eval_users = sorted(recs_hybrid['user_id'].unique())\n",
    "\n",
    "# ---------- Build sparse matrices ----------\n",
    "# ratings pivot (users x items)\n",
    "rows = rates['user_id'].map(uid2idx)\n",
    "cols = rates['video_id'].map(iid2idx)\n",
    "data = rates['rating_score'].astype(float)\n",
    "n_users, n_items = len(users), len(items)\n",
    "R = sparse.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "# Helpers\n",
    "videos_tags = videos.set_index('video_id')['specialities'].fillna('')\n",
    "def split_tags(s):\n",
    "    return [t.strip().lower() for t in str(s).split('|') if t.strip()]\n",
    "videos_taglist = videos['video_id'].map(videos_tags).apply(split_tags)\n",
    "vid2tags = dict(zip(videos['video_id'], videos_taglist))\n",
    "\n",
    "behav_click = behav[behav['action_type']=='click'][['user_id','video_id']].copy()\n",
    "behav_watch = behav[behav['action_type']=='watch'][['user_id','video_id']].copy()\n",
    "\n",
    "# ---------- UserCF (cosine on users) ----------\n",
    "# normalize user vectors\n",
    "R_user_norm = normalize(R, norm='l2', axis=1, copy=True)\n",
    "\n",
    "def usercf_topk_for_user(user_id, K=10):\n",
    "    if user_id not in uid2idx:\n",
    "        return pd.DataFrame(columns=['user_id','video_id','score'])\n",
    "    uidx = uid2idx[user_id]\n",
    "    uvec = R_user_norm[uidx]  # 1 x n_items\n",
    "    # user similarities: all_users x 1 = R_user_norm * uvec.T\n",
    "    sims = R_user_norm.dot(uvec.T).toarray().ravel()\n",
    "    sims[uidx] = 0.0  # remove self\n",
    "    # scores for items: sims^T * R  -> (1 x users) * (users x items)\n",
    "    scores = sims @ R.toarray()  # convert small? n_users x n_items might be big; try sparse\n",
    "    # To avoid memory blow, compute via sparse multiplication\n",
    "    # Fallback: if toarray caused mem issue, compute with sparse\n",
    "    # (we keep it; dataset seems small enough)\n",
    "    # mask seen items\n",
    "    seen = R[uidx].indices\n",
    "    scores[seen] = -np.inf\n",
    "    # top-K\n",
    "    top_idx = np.argpartition(scores, -K)[-K:]\n",
    "    top_idx = top_idx[np.argsort(scores[top_idx])][::-1]\n",
    "    vids = [idx2iid[i] for i in top_idx]\n",
    "    scs = scores[top_idx]\n",
    "    return pd.DataFrame({'user_id': user_id, 'video_id': vids, 'score': scs})\n",
    "\n",
    "# ---------- ItemCF (cosine on items) ----------\n",
    "# item-user matrix\n",
    "M = R.T.tocsr()  # n_items x n_users\n",
    "M_norm = normalize(M, norm='l2', axis=1, copy=True)\n",
    "\n",
    "def itemcf_topk_for_user(user_id, K=10):\n",
    "    if user_id not in uid2idx:\n",
    "        return pd.DataFrame(columns=['user_id','video_id','score'])\n",
    "    uidx = uid2idx[user_id]\n",
    "    # items rated by user and their ratings\n",
    "    start, end = R.indptr[uidx], R.indptr[uidx+1]\n",
    "    rated_item_idx = R.indices[start:end]\n",
    "    rated_scores = R.data[start:end]\n",
    "    if len(rated_item_idx)==0:\n",
    "        return pd.DataFrame(columns=['user_id','video_id','score'])\n",
    "\n",
    "    # accumulate similarity * rating via sparse ops\n",
    "    # For each rated item j: v = M_norm[j] * M_norm.T (1 x items), score += r_uj * v\n",
    "    # Efficiently: stack rows then do weighted sum\n",
    "    rows_stack = M_norm[rated_item_idx]        # k x n_users\n",
    "    # item-item sims = rows_stack * M_norm.T => k x n_items\n",
    "    sims = rows_stack @ M_norm.T               # sparse x sparse -> sparse\n",
    "    # weight by user ratings\n",
    "    # convert ratings to column vector and do weighted sum over axis 0\n",
    "    weights = sparse.csr_matrix(rated_scores.reshape(-1,1))  # k x 1\n",
    "    scores_matrix = weights.T @ sims   # 1 x n_items\n",
    "    scores = np.asarray(scores_matrix.todense()).ravel()\n",
    "\n",
    "    # remove seen items\n",
    "    scores[rated_item_idx] = -np.inf\n",
    "\n",
    "    # top-K\n",
    "    top_idx = np.argpartition(scores, -K)[-K:]\n",
    "    top_idx = top_idx[np.argsort(scores[top_idx])][::-1]\n",
    "    vids = [idx2iid[i] for i in top_idx]\n",
    "    scs = scores[top_idx]\n",
    "    return pd.DataFrame({'user_id': user_id, 'video_id': vids, 'score': scs})\n",
    "\n",
    "# ---------- Batch generate Top-10 for eval_users ----------\n",
    "def batch_recommend(generator_func, name, K=10, limit=None):\n",
    "    out = []\n",
    "    count = 0\n",
    "    for uid in eval_users:\n",
    "        df = generator_func(uid, K=K)\n",
    "        if not df.empty:\n",
    "            out.append(df[['user_id','video_id','score']].assign(rank=np.arange(1, len(df)+1)))\n",
    "        count += 1\n",
    "        if limit and count>=limit:\n",
    "            break\n",
    "    if out:\n",
    "        res = pd.concat(out, ignore_index=True)\n",
    "        res['model'] = name\n",
    "    else:\n",
    "        res = pd.DataFrame(columns=['user_id','video_id','score','rank','model'])\n",
    "    return res\n",
    "\n",
    "usercf_recs = batch_recommend(usercf_topk_for_user, \"UserCF\", K=10)\n",
    "itemcf_recs = batch_recommend(itemcf_topk_for_user, \"ItemCF\", K=10)\n",
    "\n",
    "# Map Hybrid to same schema\n",
    "hybrid_small = recs_hybrid[['user_id','video_id','hybrid_score','rank']].copy()\n",
    "hybrid_small = hybrid_small.rename(columns={'hybrid_score':'score'})\n",
    "hybrid_small['model'] = 'Hybrid'\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "def split_tags(s):\n",
    "    return [t.strip().lower() for t in str(s).split('|') if t.strip()]\n",
    "\n",
    "videos_tagmap = videos.set_index('video_id')['specialities'].fillna('').map(split_tags).to_dict()\n",
    "\n",
    "def metrics_for(recs_df, behav_click, behav_watch, videos_tagmap, catalog_size):\n",
    "    if recs_df.empty:\n",
    "        return {\n",
    "            \"coverage\": 0.0, \"global_tag_entropy\": np.nan,\n",
    "            \"avg_unique_tags_per_user\": np.nan, \"avg_intra_list_jaccard\": np.nan,\n",
    "            \"ctr\": np.nan, \"watch_rate\": np.nan, \"rows\": 0\n",
    "        }\n",
    "    # coverage\n",
    "    coverage = recs_df['video_id'].nunique() / catalog_size\n",
    "\n",
    "    # diversity\n",
    "    recs_df = recs_df.copy()\n",
    "    recs_df['tags'] = recs_df['video_id'].map(videos_tagmap).apply(lambda x: x if isinstance(x, list) else [])\n",
    "    all_tags = [t for ts in recs_df['tags'] for t in ts]\n",
    "    tag_counts = Counter(all_tags)\n",
    "    probs = np.array(list(tag_counts.values()), dtype=float)\n",
    "    probs = probs / probs.sum() if probs.sum()>0 else probs\n",
    "    global_tag_entropy = float(-(probs * np.log(probs + 1e-12)).sum()) if probs.size>0 else np.nan\n",
    "\n",
    "    # per-user diversity\n",
    "    def user_div(df):\n",
    "        tags_list = df['tags'].tolist()\n",
    "        uniq = set()\n",
    "        for ts in tags_list:\n",
    "            uniq |= set(ts)\n",
    "        # jaccard\n",
    "        sims = []\n",
    "        for i in range(len(tags_list)):\n",
    "            for j in range(i+1, len(tags_list)):\n",
    "                a, b = set(tags_list[i]), set(tags_list[j])\n",
    "                if len(a)==0 and len(b)==0:\n",
    "                    sims.append(1.0)\n",
    "                else:\n",
    "                    sims.append(len(a & b) / (len(a | b)) if len(a | b)>0 else 0.0)\n",
    "        return pd.Series({'unique_tags': len(uniq), 'avg_jaccard': np.mean(sims) if sims else np.nan})\n",
    "    user_div_df = recs_df.groupby('user_id').apply(user_div).reset_index()\n",
    "    avg_unique_tags = float(user_div_df['unique_tags'].mean())\n",
    "    avg_jaccard = float(user_div_df['avg_jaccard'].mean())\n",
    "\n",
    "    # CTR / Watch\n",
    "    key = recs_df[['user_id','video_id']].copy().drop_duplicates()\n",
    "    clicked = key.merge(behav_click, on=['user_id','video_id'], how='left', indicator=True)\n",
    "    watched = key.merge(behav_watch, on=['user_id','video_id'], how='left', indicator=True)\n",
    "    ctr = (clicked['_merge']=='both').mean()\n",
    "    watch_rate = (watched['_merge']=='both').mean()\n",
    "\n",
    "    return {\n",
    "        \"coverage\": float(coverage),\n",
    "        \"global_tag_entropy\": global_tag_entropy,\n",
    "        \"avg_unique_tags_per_user\": avg_unique_tags,\n",
    "        \"avg_intra_list_jaccard\": avg_jaccard,\n",
    "        \"ctr\": float(ctr),\n",
    "        \"watch_rate\": float(watch_rate),\n",
    "        \"rows\": int(len(recs_df))\n",
    "    }\n",
    "\n",
    "catalog_size = videos['video_id'].nunique()\n",
    "\n",
    "m_hybrid = metrics_for(hybrid_small, behav_click, behav_watch, videos_tagmap, catalog_size)\n",
    "m_usercf = metrics_for(usercf_recs, behav_click, behav_watch, videos_tagmap, catalog_size)\n",
    "m_itemcf = metrics_for(itemcf_recs, behav_click, behav_watch, videos_tagmap, catalog_size)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"model\":\"Hybrid\", **m_hybrid},\n",
    "    {\"model\":\"UserCF\", **m_usercf},\n",
    "    {\"model\":\"ItemCF\", **m_itemcf},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa551da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
